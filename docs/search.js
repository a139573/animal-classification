window.pdocSearch = (function(){
/** elasticlunr - http://weixsong.github.io * Copyright (C) 2017 Oliver Nightingale * Copyright (C) 2017 Wei Song * MIT Licensed */!function(){function e(e){if(null===e||"object"!=typeof e)return e;var t=e.constructor();for(var n in e)e.hasOwnProperty(n)&&(t[n]=e[n]);return t}var t=function(e){var n=new t.Index;return n.pipeline.add(t.trimmer,t.stopWordFilter,t.stemmer),e&&e.call(n,n),n};t.version="0.9.5",lunr=t,t.utils={},t.utils.warn=function(e){return function(t){e.console&&console.warn&&console.warn(t)}}(this),t.utils.toString=function(e){return void 0===e||null===e?"":e.toString()},t.EventEmitter=function(){this.events={}},t.EventEmitter.prototype.addListener=function(){var e=Array.prototype.slice.call(arguments),t=e.pop(),n=e;if("function"!=typeof t)throw new TypeError("last argument must be a function");n.forEach(function(e){this.hasHandler(e)||(this.events[e]=[]),this.events[e].push(t)},this)},t.EventEmitter.prototype.removeListener=function(e,t){if(this.hasHandler(e)){var n=this.events[e].indexOf(t);-1!==n&&(this.events[e].splice(n,1),0==this.events[e].length&&delete this.events[e])}},t.EventEmitter.prototype.emit=function(e){if(this.hasHandler(e)){var t=Array.prototype.slice.call(arguments,1);this.events[e].forEach(function(e){e.apply(void 0,t)},this)}},t.EventEmitter.prototype.hasHandler=function(e){return e in this.events},t.tokenizer=function(e){if(!arguments.length||null===e||void 0===e)return[];if(Array.isArray(e)){var n=e.filter(function(e){return null===e||void 0===e?!1:!0});n=n.map(function(e){return t.utils.toString(e).toLowerCase()});var i=[];return n.forEach(function(e){var n=e.split(t.tokenizer.seperator);i=i.concat(n)},this),i}return e.toString().trim().toLowerCase().split(t.tokenizer.seperator)},t.tokenizer.defaultSeperator=/[\s\-]+/,t.tokenizer.seperator=t.tokenizer.defaultSeperator,t.tokenizer.setSeperator=function(e){null!==e&&void 0!==e&&"object"==typeof e&&(t.tokenizer.seperator=e)},t.tokenizer.resetSeperator=function(){t.tokenizer.seperator=t.tokenizer.defaultSeperator},t.tokenizer.getSeperator=function(){return t.tokenizer.seperator},t.Pipeline=function(){this._queue=[]},t.Pipeline.registeredFunctions={},t.Pipeline.registerFunction=function(e,n){n in t.Pipeline.registeredFunctions&&t.utils.warn("Overwriting existing registered function: "+n),e.label=n,t.Pipeline.registeredFunctions[n]=e},t.Pipeline.getRegisteredFunction=function(e){return e in t.Pipeline.registeredFunctions!=!0?null:t.Pipeline.registeredFunctions[e]},t.Pipeline.warnIfFunctionNotRegistered=function(e){var n=e.label&&e.label in this.registeredFunctions;n||t.utils.warn("Function is not registered with pipeline. This may cause problems when serialising the index.\n",e)},t.Pipeline.load=function(e){var n=new t.Pipeline;return e.forEach(function(e){var i=t.Pipeline.getRegisteredFunction(e);if(!i)throw new Error("Cannot load un-registered function: "+e);n.add(i)}),n},t.Pipeline.prototype.add=function(){var e=Array.prototype.slice.call(arguments);e.forEach(function(e){t.Pipeline.warnIfFunctionNotRegistered(e),this._queue.push(e)},this)},t.Pipeline.prototype.after=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i+1,0,n)},t.Pipeline.prototype.before=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i,0,n)},t.Pipeline.prototype.remove=function(e){var t=this._queue.indexOf(e);-1!==t&&this._queue.splice(t,1)},t.Pipeline.prototype.run=function(e){for(var t=[],n=e.length,i=this._queue.length,o=0;n>o;o++){for(var r=e[o],s=0;i>s&&(r=this._queue[s](r,o,e),void 0!==r&&null!==r);s++);void 0!==r&&null!==r&&t.push(r)}return t},t.Pipeline.prototype.reset=function(){this._queue=[]},t.Pipeline.prototype.get=function(){return this._queue},t.Pipeline.prototype.toJSON=function(){return this._queue.map(function(e){return t.Pipeline.warnIfFunctionNotRegistered(e),e.label})},t.Index=function(){this._fields=[],this._ref="id",this.pipeline=new t.Pipeline,this.documentStore=new t.DocumentStore,this.index={},this.eventEmitter=new t.EventEmitter,this._idfCache={},this.on("add","remove","update",function(){this._idfCache={}}.bind(this))},t.Index.prototype.on=function(){var e=Array.prototype.slice.call(arguments);return this.eventEmitter.addListener.apply(this.eventEmitter,e)},t.Index.prototype.off=function(e,t){return this.eventEmitter.removeListener(e,t)},t.Index.load=function(e){e.version!==t.version&&t.utils.warn("version mismatch: current "+t.version+" importing "+e.version);var n=new this;n._fields=e.fields,n._ref=e.ref,n.documentStore=t.DocumentStore.load(e.documentStore),n.pipeline=t.Pipeline.load(e.pipeline),n.index={};for(var i in e.index)n.index[i]=t.InvertedIndex.load(e.index[i]);return n},t.Index.prototype.addField=function(e){return this._fields.push(e),this.index[e]=new t.InvertedIndex,this},t.Index.prototype.setRef=function(e){return this._ref=e,this},t.Index.prototype.saveDocument=function(e){return this.documentStore=new t.DocumentStore(e),this},t.Index.prototype.addDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.addDoc(i,e),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));this.documentStore.addFieldLength(i,n,o.length);var r={};o.forEach(function(e){e in r?r[e]+=1:r[e]=1},this);for(var s in r){var u=r[s];u=Math.sqrt(u),this.index[n].addToken(s,{ref:i,tf:u})}},this),n&&this.eventEmitter.emit("add",e,this)}},t.Index.prototype.removeDocByRef=function(e){if(e&&this.documentStore.isDocStored()!==!1&&this.documentStore.hasDoc(e)){var t=this.documentStore.getDoc(e);this.removeDoc(t,!1)}},t.Index.prototype.removeDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.hasDoc(i)&&(this.documentStore.removeDoc(i),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));o.forEach(function(e){this.index[n].removeToken(e,i)},this)},this),n&&this.eventEmitter.emit("remove",e,this))}},t.Index.prototype.updateDoc=function(e,t){var t=void 0===t?!0:t;this.removeDocByRef(e[this._ref],!1),this.addDoc(e,!1),t&&this.eventEmitter.emit("update",e,this)},t.Index.prototype.idf=function(e,t){var n="@"+t+"/"+e;if(Object.prototype.hasOwnProperty.call(this._idfCache,n))return this._idfCache[n];var i=this.index[t].getDocFreq(e),o=1+Math.log(this.documentStore.length/(i+1));return this._idfCache[n]=o,o},t.Index.prototype.getFields=function(){return this._fields.slice()},t.Index.prototype.search=function(e,n){if(!e)return[];e="string"==typeof e?{any:e}:JSON.parse(JSON.stringify(e));var i=null;null!=n&&(i=JSON.stringify(n));for(var o=new t.Configuration(i,this.getFields()).get(),r={},s=Object.keys(e),u=0;u<s.length;u++){var a=s[u];r[a]=this.pipeline.run(t.tokenizer(e[a]))}var l={};for(var c in o){var d=r[c]||r.any;if(d){var f=this.fieldSearch(d,c,o),h=o[c].boost;for(var p in f)f[p]=f[p]*h;for(var p in f)p in l?l[p]+=f[p]:l[p]=f[p]}}var v,g=[];for(var p in l)v={ref:p,score:l[p]},this.documentStore.hasDoc(p)&&(v.doc=this.documentStore.getDoc(p)),g.push(v);return g.sort(function(e,t){return t.score-e.score}),g},t.Index.prototype.fieldSearch=function(e,t,n){var i=n[t].bool,o=n[t].expand,r=n[t].boost,s=null,u={};return 0!==r?(e.forEach(function(e){var n=[e];1==o&&(n=this.index[t].expandToken(e));var r={};n.forEach(function(n){var o=this.index[t].getDocs(n),a=this.idf(n,t);if(s&&"AND"==i){var l={};for(var c in s)c in o&&(l[c]=o[c]);o=l}n==e&&this.fieldSearchStats(u,n,o);for(var c in o){var d=this.index[t].getTermFrequency(n,c),f=this.documentStore.getFieldLength(c,t),h=1;0!=f&&(h=1/Math.sqrt(f));var p=1;n!=e&&(p=.15*(1-(n.length-e.length)/n.length));var v=d*a*h*p;c in r?r[c]+=v:r[c]=v}},this),s=this.mergeScores(s,r,i)},this),s=this.coordNorm(s,u,e.length)):void 0},t.Index.prototype.mergeScores=function(e,t,n){if(!e)return t;if("AND"==n){var i={};for(var o in t)o in e&&(i[o]=e[o]+t[o]);return i}for(var o in t)o in e?e[o]+=t[o]:e[o]=t[o];return e},t.Index.prototype.fieldSearchStats=function(e,t,n){for(var i in n)i in e?e[i].push(t):e[i]=[t]},t.Index.prototype.coordNorm=function(e,t,n){for(var i in e)if(i in t){var o=t[i].length;e[i]=e[i]*o/n}return e},t.Index.prototype.toJSON=function(){var e={};return this._fields.forEach(function(t){e[t]=this.index[t].toJSON()},this),{version:t.version,fields:this._fields,ref:this._ref,documentStore:this.documentStore.toJSON(),index:e,pipeline:this.pipeline.toJSON()}},t.Index.prototype.use=function(e){var t=Array.prototype.slice.call(arguments,1);t.unshift(this),e.apply(this,t)},t.DocumentStore=function(e){this._save=null===e||void 0===e?!0:e,this.docs={},this.docInfo={},this.length=0},t.DocumentStore.load=function(e){var t=new this;return t.length=e.length,t.docs=e.docs,t.docInfo=e.docInfo,t._save=e.save,t},t.DocumentStore.prototype.isDocStored=function(){return this._save},t.DocumentStore.prototype.addDoc=function(t,n){this.hasDoc(t)||this.length++,this.docs[t]=this._save===!0?e(n):null},t.DocumentStore.prototype.getDoc=function(e){return this.hasDoc(e)===!1?null:this.docs[e]},t.DocumentStore.prototype.hasDoc=function(e){return e in this.docs},t.DocumentStore.prototype.removeDoc=function(e){this.hasDoc(e)&&(delete this.docs[e],delete this.docInfo[e],this.length--)},t.DocumentStore.prototype.addFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&(this.docInfo[e]||(this.docInfo[e]={}),this.docInfo[e][t]=n)},t.DocumentStore.prototype.updateFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&this.addFieldLength(e,t,n)},t.DocumentStore.prototype.getFieldLength=function(e,t){return null===e||void 0===e?0:e in this.docs&&t in this.docInfo[e]?this.docInfo[e][t]:0},t.DocumentStore.prototype.toJSON=function(){return{docs:this.docs,docInfo:this.docInfo,length:this.length,save:this._save}},t.stemmer=function(){var e={ational:"ate",tional:"tion",enci:"ence",anci:"ance",izer:"ize",bli:"ble",alli:"al",entli:"ent",eli:"e",ousli:"ous",ization:"ize",ation:"ate",ator:"ate",alism:"al",iveness:"ive",fulness:"ful",ousness:"ous",aliti:"al",iviti:"ive",biliti:"ble",logi:"log"},t={icate:"ic",ative:"",alize:"al",iciti:"ic",ical:"ic",ful:"",ness:""},n="[^aeiou]",i="[aeiouy]",o=n+"[^aeiouy]*",r=i+"[aeiou]*",s="^("+o+")?"+r+o,u="^("+o+")?"+r+o+"("+r+")?$",a="^("+o+")?"+r+o+r+o,l="^("+o+")?"+i,c=new RegExp(s),d=new RegExp(a),f=new RegExp(u),h=new RegExp(l),p=/^(.+?)(ss|i)es$/,v=/^(.+?)([^s])s$/,g=/^(.+?)eed$/,m=/^(.+?)(ed|ing)$/,y=/.$/,S=/(at|bl|iz)$/,x=new RegExp("([^aeiouylsz])\\1$"),w=new RegExp("^"+o+i+"[^aeiouwxy]$"),I=/^(.+?[^aeiou])y$/,b=/^(.+?)(ational|tional|enci|anci|izer|bli|alli|entli|eli|ousli|ization|ation|ator|alism|iveness|fulness|ousness|aliti|iviti|biliti|logi)$/,E=/^(.+?)(icate|ative|alize|iciti|ical|ful|ness)$/,D=/^(.+?)(al|ance|ence|er|ic|able|ible|ant|ement|ment|ent|ou|ism|ate|iti|ous|ive|ize)$/,F=/^(.+?)(s|t)(ion)$/,_=/^(.+?)e$/,P=/ll$/,k=new RegExp("^"+o+i+"[^aeiouwxy]$"),z=function(n){var i,o,r,s,u,a,l;if(n.length<3)return n;if(r=n.substr(0,1),"y"==r&&(n=r.toUpperCase()+n.substr(1)),s=p,u=v,s.test(n)?n=n.replace(s,"$1$2"):u.test(n)&&(n=n.replace(u,"$1$2")),s=g,u=m,s.test(n)){var z=s.exec(n);s=c,s.test(z[1])&&(s=y,n=n.replace(s,""))}else if(u.test(n)){var z=u.exec(n);i=z[1],u=h,u.test(i)&&(n=i,u=S,a=x,l=w,u.test(n)?n+="e":a.test(n)?(s=y,n=n.replace(s,"")):l.test(n)&&(n+="e"))}if(s=I,s.test(n)){var z=s.exec(n);i=z[1],n=i+"i"}if(s=b,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+e[o])}if(s=E,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+t[o])}if(s=D,u=F,s.test(n)){var z=s.exec(n);i=z[1],s=d,s.test(i)&&(n=i)}else if(u.test(n)){var z=u.exec(n);i=z[1]+z[2],u=d,u.test(i)&&(n=i)}if(s=_,s.test(n)){var z=s.exec(n);i=z[1],s=d,u=f,a=k,(s.test(i)||u.test(i)&&!a.test(i))&&(n=i)}return s=P,u=d,s.test(n)&&u.test(n)&&(s=y,n=n.replace(s,"")),"y"==r&&(n=r.toLowerCase()+n.substr(1)),n};return z}(),t.Pipeline.registerFunction(t.stemmer,"stemmer"),t.stopWordFilter=function(e){return e&&t.stopWordFilter.stopWords[e]!==!0?e:void 0},t.clearStopWords=function(){t.stopWordFilter.stopWords={}},t.addStopWords=function(e){null!=e&&Array.isArray(e)!==!1&&e.forEach(function(e){t.stopWordFilter.stopWords[e]=!0},this)},t.resetStopWords=function(){t.stopWordFilter.stopWords=t.defaultStopWords},t.defaultStopWords={"":!0,a:!0,able:!0,about:!0,across:!0,after:!0,all:!0,almost:!0,also:!0,am:!0,among:!0,an:!0,and:!0,any:!0,are:!0,as:!0,at:!0,be:!0,because:!0,been:!0,but:!0,by:!0,can:!0,cannot:!0,could:!0,dear:!0,did:!0,"do":!0,does:!0,either:!0,"else":!0,ever:!0,every:!0,"for":!0,from:!0,get:!0,got:!0,had:!0,has:!0,have:!0,he:!0,her:!0,hers:!0,him:!0,his:!0,how:!0,however:!0,i:!0,"if":!0,"in":!0,into:!0,is:!0,it:!0,its:!0,just:!0,least:!0,let:!0,like:!0,likely:!0,may:!0,me:!0,might:!0,most:!0,must:!0,my:!0,neither:!0,no:!0,nor:!0,not:!0,of:!0,off:!0,often:!0,on:!0,only:!0,or:!0,other:!0,our:!0,own:!0,rather:!0,said:!0,say:!0,says:!0,she:!0,should:!0,since:!0,so:!0,some:!0,than:!0,that:!0,the:!0,their:!0,them:!0,then:!0,there:!0,these:!0,they:!0,"this":!0,tis:!0,to:!0,too:!0,twas:!0,us:!0,wants:!0,was:!0,we:!0,were:!0,what:!0,when:!0,where:!0,which:!0,"while":!0,who:!0,whom:!0,why:!0,will:!0,"with":!0,would:!0,yet:!0,you:!0,your:!0},t.stopWordFilter.stopWords=t.defaultStopWords,t.Pipeline.registerFunction(t.stopWordFilter,"stopWordFilter"),t.trimmer=function(e){if(null===e||void 0===e)throw new Error("token should not be undefined");return e.replace(/^\W+/,"").replace(/\W+$/,"")},t.Pipeline.registerFunction(t.trimmer,"trimmer"),t.InvertedIndex=function(){this.root={docs:{},df:0}},t.InvertedIndex.load=function(e){var t=new this;return t.root=e.root,t},t.InvertedIndex.prototype.addToken=function(e,t,n){for(var n=n||this.root,i=0;i<=e.length-1;){var o=e[i];o in n||(n[o]={docs:{},df:0}),i+=1,n=n[o]}var r=t.ref;n.docs[r]?n.docs[r]={tf:t.tf}:(n.docs[r]={tf:t.tf},n.df+=1)},t.InvertedIndex.prototype.hasToken=function(e){if(!e)return!1;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return!1;t=t[e[n]]}return!0},t.InvertedIndex.prototype.getNode=function(e){if(!e)return null;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return null;t=t[e[n]]}return t},t.InvertedIndex.prototype.getDocs=function(e){var t=this.getNode(e);return null==t?{}:t.docs},t.InvertedIndex.prototype.getTermFrequency=function(e,t){var n=this.getNode(e);return null==n?0:t in n.docs?n.docs[t].tf:0},t.InvertedIndex.prototype.getDocFreq=function(e){var t=this.getNode(e);return null==t?0:t.df},t.InvertedIndex.prototype.removeToken=function(e,t){if(e){var n=this.getNode(e);null!=n&&t in n.docs&&(delete n.docs[t],n.df-=1)}},t.InvertedIndex.prototype.expandToken=function(e,t,n){if(null==e||""==e)return[];var t=t||[];if(void 0==n&&(n=this.getNode(e),null==n))return t;n.df>0&&t.push(e);for(var i in n)"docs"!==i&&"df"!==i&&this.expandToken(e+i,t,n[i]);return t},t.InvertedIndex.prototype.toJSON=function(){return{root:this.root}},t.Configuration=function(e,n){var e=e||"";if(void 0==n||null==n)throw new Error("fields should not be null");this.config={};var i;try{i=JSON.parse(e),this.buildUserConfig(i,n)}catch(o){t.utils.warn("user configuration parse failed, will use default configuration"),this.buildDefaultConfig(n)}},t.Configuration.prototype.buildDefaultConfig=function(e){this.reset(),e.forEach(function(e){this.config[e]={boost:1,bool:"OR",expand:!1}},this)},t.Configuration.prototype.buildUserConfig=function(e,n){var i="OR",o=!1;if(this.reset(),"bool"in e&&(i=e.bool||i),"expand"in e&&(o=e.expand||o),"fields"in e)for(var r in e.fields)if(n.indexOf(r)>-1){var s=e.fields[r],u=o;void 0!=s.expand&&(u=s.expand),this.config[r]={boost:s.boost||0===s.boost?s.boost:1,bool:s.bool||i,expand:u}}else t.utils.warn("field name in user configuration not found in index instance fields");else this.addAllFields2UserConfig(i,o,n)},t.Configuration.prototype.addAllFields2UserConfig=function(e,t,n){n.forEach(function(n){this.config[n]={boost:1,bool:e,expand:t}},this)},t.Configuration.prototype.get=function(){return this.config},t.Configuration.prototype.reset=function(){this.config={}},lunr.SortedSet=function(){this.length=0,this.elements=[]},lunr.SortedSet.load=function(e){var t=new this;return t.elements=e,t.length=e.length,t},lunr.SortedSet.prototype.add=function(){var e,t;for(e=0;e<arguments.length;e++)t=arguments[e],~this.indexOf(t)||this.elements.splice(this.locationFor(t),0,t);this.length=this.elements.length},lunr.SortedSet.prototype.toArray=function(){return this.elements.slice()},lunr.SortedSet.prototype.map=function(e,t){return this.elements.map(e,t)},lunr.SortedSet.prototype.forEach=function(e,t){return this.elements.forEach(e,t)},lunr.SortedSet.prototype.indexOf=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;){if(r===e)return o;e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o]}return r===e?o:-1},lunr.SortedSet.prototype.locationFor=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;)e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o];return r>e?o:e>r?o+1:void 0},lunr.SortedSet.prototype.intersect=function(e){for(var t=new lunr.SortedSet,n=0,i=0,o=this.length,r=e.length,s=this.elements,u=e.elements;;){if(n>o-1||i>r-1)break;s[n]!==u[i]?s[n]<u[i]?n++:s[n]>u[i]&&i++:(t.add(s[n]),n++,i++)}return t},lunr.SortedSet.prototype.clone=function(){var e=new lunr.SortedSet;return e.elements=this.toArray(),e.length=e.elements.length,e},lunr.SortedSet.prototype.union=function(e){var t,n,i;this.length>=e.length?(t=this,n=e):(t=e,n=this),i=t.clone();for(var o=0,r=n.toArray();o<r.length;o++)i.add(r[o]);return i},lunr.SortedSet.prototype.toJSON=function(){return this.toArray()},function(e,t){"function"==typeof define&&define.amd?define(t):"object"==typeof exports?module.exports=t():e.elasticlunr=t()}(this,function(){return t})}();
    /** pdoc search index */const docs = [{"fullname": "my_projects", "modulename": "my_projects", "kind": "module", "doc": "<p>Animal Classification Project (my_projects)</p>\n\n<p>This is the main package for the project. It contains all modules\nrequired for the Machine Learning pipeline.</p>\n\n<h3 id=\"submodules\">Submodules</h3>\n\n<ul>\n<li><strong>dataset</strong>: Functions for loading and processing the dataset.</li>\n<li><strong>download_data</strong>: Script to download the initial data.</li>\n<li><strong>modeling</strong>: Model definition, training, and evaluation.</li>\n<li><strong>plots</strong>: Functions for generating visualizations.</li>\n<li><strong>reduce_data</strong>: Scripts for dimensionality reduction.</li>\n<li><strong>scripts</strong>: Other helper scripts.</li>\n</ul>\n"}, {"fullname": "my_projects.dataset", "modulename": "my_projects.dataset", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "my_projects.dataset.AnimalsDataModule", "modulename": "my_projects.dataset", "qualname": "AnimalsDataModule", "kind": "class", "doc": "<p>PyTorch Lightning DataModule for an animal classification dataset.</p>\n\n<p>This class handles the loading, transformation, and splitting (training,\nvalidation, test) of the image dataset.</p>\n", "bases": "pytorch_lightning.core.datamodule.LightningDataModule"}, {"fullname": "my_projects.dataset.AnimalsDataModule.__init__", "modulename": "my_projects.dataset", "qualname": "AnimalsDataModule.__init__", "kind": "function", "doc": "<p>Initializes the DataModule.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>data_dir : str, optional\n    Directory containing the dataset (default is \".\").\nbatch_size : int, optional\n    Batch size for the DataLoaders (default is 32).\nnum_workers : int, optional\n    Number of workers for the DataLoaders (default is 4).\ntest_frac : float, optional\n    Fraction of the dataset to reserve for testing (default is 0.2).\nseed : int, optional\n    Random seed for data splitting (default is 123).</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">data_dir</span><span class=\"o\">=</span><span class=\"s1\">&#39;.&#39;</span>, </span><span class=\"param\"><span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"mi\">32</span>, </span><span class=\"param\"><span class=\"n\">num_workers</span><span class=\"o\">=</span><span class=\"mi\">4</span>, </span><span class=\"param\"><span class=\"n\">test_frac</span><span class=\"o\">=</span><span class=\"mf\">0.2</span>, </span><span class=\"param\"><span class=\"n\">seed</span><span class=\"o\">=</span><span class=\"mi\">123</span></span>)</span>"}, {"fullname": "my_projects.dataset.AnimalsDataModule.data_dir", "modulename": "my_projects.dataset", "qualname": "AnimalsDataModule.data_dir", "kind": "variable", "doc": "<p>Path to the data directory.</p>\n"}, {"fullname": "my_projects.dataset.AnimalsDataModule.batch_size", "modulename": "my_projects.dataset", "qualname": "AnimalsDataModule.batch_size", "kind": "variable", "doc": "<p>Number of samples per batch.</p>\n"}, {"fullname": "my_projects.dataset.AnimalsDataModule.num_workers", "modulename": "my_projects.dataset", "qualname": "AnimalsDataModule.num_workers", "kind": "variable", "doc": "<p>Number of subprocesses for data loading.</p>\n"}, {"fullname": "my_projects.dataset.AnimalsDataModule.test_frac", "modulename": "my_projects.dataset", "qualname": "AnimalsDataModule.test_frac", "kind": "variable", "doc": "<p>Fraction of the dataset to reserve for testing.</p>\n"}, {"fullname": "my_projects.dataset.AnimalsDataModule.seed", "modulename": "my_projects.dataset", "qualname": "AnimalsDataModule.seed", "kind": "variable", "doc": "<p>Random seed for data splitting.</p>\n"}, {"fullname": "my_projects.dataset.AnimalsDataModule.transform", "modulename": "my_projects.dataset", "qualname": "AnimalsDataModule.transform", "kind": "variable", "doc": "<p>Transformations applied to each image.</p>\n"}, {"fullname": "my_projects.dataset.AnimalsDataModule.setup", "modulename": "my_projects.dataset", "qualname": "AnimalsDataModule.setup", "kind": "function", "doc": "<p>Prepares the data and performs the train/val/test split.</p>\n\n<p>This method is called automatically by PyTorch Lightning. It loads the\nfull dataset, calculates the splits, and assigns the\n<code>train_data</code>, <code>val_data</code>, and <code>test_data</code> subsets.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>stage : str, optional\n    Lightning stage (e.g., \"fit\", \"test\"). Not used in this\n    implementation, as the data is split only once.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">stage</span><span class=\"o\">=</span><span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "my_projects.dataset.AnimalsDataModule.train_dataloader", "modulename": "my_projects.dataset", "qualname": "AnimalsDataModule.train_dataloader", "kind": "function", "doc": "<p>Creates the DataLoader for the training set.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>torch.utils.data.DataLoader\n    The training DataLoader, with shuffling (shuffle=True).</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "my_projects.dataset.AnimalsDataModule.val_dataloader", "modulename": "my_projects.dataset", "qualname": "AnimalsDataModule.val_dataloader", "kind": "function", "doc": "<p>Creates the DataLoader for the validation set.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>torch.utils.data.DataLoader\n    The validation DataLoader (shuffle=False).</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "my_projects.dataset.AnimalsDataModule.test_dataloader", "modulename": "my_projects.dataset", "qualname": "AnimalsDataModule.test_dataloader", "kind": "function", "doc": "<p>Creates the DataLoader for the test set.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>torch.utils.data.DataLoader\n    The test DataLoader (shuffle=False).</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "my_projects.download_data", "modulename": "my_projects.download_data", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "my_projects.download_data.flatten_folder", "modulename": "my_projects.download_data", "qualname": "flatten_folder", "kind": "function", "doc": "<p>Recursively flattens a directory structure.</p>\n\n<p>If a folder contains exactly one subfolder and no files,\nthis function descends into that subfolder. This process is\nrepeated until the directory contains multiple items (files or\nother folders). This is useful for \"unwrapping\" archives\nthat have a redundant top-level folder.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>path : Path\n    The starting directory path to flatten.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>Path\n    The path to the \"real\" content folder.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">path</span><span class=\"p\">:</span> <span class=\"n\">pathlib</span><span class=\"o\">.</span><span class=\"n\">_local</span><span class=\"o\">.</span><span class=\"n\">Path</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pathlib</span><span class=\"o\">.</span><span class=\"n\">_local</span><span class=\"o\">.</span><span class=\"n\">Path</span>:</span></span>", "funcdef": "def"}, {"fullname": "my_projects.download_data.main", "modulename": "my_projects.download_data", "qualname": "main", "kind": "function", "doc": "<p>Main function to download, process, and organize the dataset.</p>\n\n<p>Downloads the Kaggle animal dataset, flattens any nested\ndirectory structures, and copies the contents (class folders)\ninto a clean 'data/animals' directory.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "my_projects.modeling", "modulename": "my_projects.modeling", "kind": "module", "doc": "<h1 id=\"modeling-package-my_projectsmodeling\">Modeling Package (my_projects.modeling)</h1>\n\n<p>This package contains all modules related to Machine Learning\nfor the project.</p>\n\n<p>This includes the model architecture definitions, the training \nprocess, and functions for performing inference.</p>\n\n<p>Submodules:</p>\n\n<ul>\n<li><strong>inference</strong>: Functions for loading a trained model and \nmaking predictions on new data.</li>\n<li><strong>train</strong>: Contains the pipeline and loops for training\nand evaluating the models.</li>\n</ul>\n"}, {"fullname": "my_projects.modeling.inference", "modulename": "my_projects.modeling.inference", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "my_projects.modeling.inference.fig_to_image", "modulename": "my_projects.modeling.inference", "qualname": "fig_to_image", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "my_projects.modeling.inference.run_inference", "modulename": "my_projects.modeling.inference", "qualname": "run_inference", "kind": "function", "doc": "<p>Run model inference on the validation dataset.<br />\nUses an in-memory model if provided, otherwise loads from checkpoint.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>trained_model : torch.nn.Module, optional\n    A trained model instance already loaded in memory.\nmodel_path : Path, optional\n    Path to a saved model state dictionary (.pth).\ndata_dir : Path, optional\n    Path to the dataset directory.\narchitecture : str, optional\n    Model architecture name (\"vgg16\" or \"vgg11\").\noutput_path : Path, optional\n    Where to save predictions and plots.\nbatch_size : int, optional\n    Validation batch size.\nis_demo : bool, optional\n    Whether to use a temporary folder for outputs (auto-cleaned).</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>dict\n    { \"val_acc\": float, \"f1_score\": float, \"confusion_matrix\": np.ndarray }</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">model_path</span><span class=\"p\">:</span> <span class=\"n\">pathlib</span><span class=\"o\">.</span><span class=\"n\">_local</span><span class=\"o\">.</span><span class=\"n\">Path</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">data_dir</span><span class=\"p\">:</span> <span class=\"n\">pathlib</span><span class=\"o\">.</span><span class=\"n\">_local</span><span class=\"o\">.</span><span class=\"n\">Path</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">architecture</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">trained_model</span><span class=\"p\">:</span> <span class=\"n\">pytorch_lightning</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">LightningModule</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">output_path</span><span class=\"p\">:</span> <span class=\"n\">pathlib</span><span class=\"o\">.</span><span class=\"n\">_local</span><span class=\"o\">.</span><span class=\"n\">Path</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">batch_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">16</span>,</span><span class=\"param\">\t<span class=\"n\">num_workers</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">2</span>,</span><span class=\"param\">\t<span class=\"n\">is_demo</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "my_projects.modeling.train", "modulename": "my_projects.modeling.train", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "my_projects.modeling.train.VGGNet", "modulename": "my_projects.modeling.train", "qualname": "VGGNet", "kind": "class", "doc": "<p>Hooks to be used in LightningModule.</p>\n", "bases": "pytorch_lightning.core.module.LightningModule"}, {"fullname": "my_projects.modeling.train.VGGNet.__init__", "modulename": "my_projects.modeling.train", "qualname": "VGGNet.__init__", "kind": "function", "doc": "<p>Attributes:\n    prepare_data_per_node:\n        If True, each LOCAL_RANK=0 will call prepare data.\n        Otherwise only NODE_RANK=0, LOCAL_RANK=0 will prepare data.\n    allow_zero_length_dataloader_with_multiple_devices:\n        If True, dataloader with zero length within local rank is allowed.\n        Default value is False.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">architecture</span><span class=\"o\">=</span><span class=\"s1\">&#39;vgg16&#39;</span>, </span><span class=\"param\"><span class=\"n\">num_classes</span><span class=\"o\">=</span><span class=\"mi\">90</span>, </span><span class=\"param\"><span class=\"n\">pretrained</span><span class=\"o\">=</span><span class=\"kc\">True</span>, </span><span class=\"param\"><span class=\"n\">lr</span><span class=\"o\">=</span><span class=\"mf\">0.001</span></span>)</span>"}, {"fullname": "my_projects.modeling.train.VGGNet.loss_fn", "modulename": "my_projects.modeling.train", "qualname": "VGGNet.loss_fn", "kind": "variable", "doc": "<p>Standard CrossEntropyLoss for classification tasks.</p>\n"}, {"fullname": "my_projects.modeling.train.VGGNet.lr", "modulename": "my_projects.modeling.train", "qualname": "VGGNet.lr", "kind": "variable", "doc": "<p>Learning rate used by the optimizer.</p>\n"}, {"fullname": "my_projects.modeling.train.VGGNet.forward", "modulename": "my_projects.modeling.train", "qualname": "VGGNet.forward", "kind": "function", "doc": "<p>Same as <code>torch.nn.Module.forward()</code>.</p>\n\n<p>Args:\n    <em>args: Whatever you decide to pass into the forward method.\n    *</em>kwargs: Keyword arguments are also possible.</p>\n\n<p>Return:\n    Your model's output</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">x</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "my_projects.modeling.train.VGGNet.training_step", "modulename": "my_projects.modeling.train", "qualname": "VGGNet.training_step", "kind": "function", "doc": "<p>Here you compute and return the training loss and some additional metrics for e.g. the progress bar or\nlogger.</p>\n\n<p>Args:\n    batch: The output of your data iterable, normally a <code>~torch.utils.data.DataLoader</code>.\n    batch_idx: The index of this batch.\n    dataloader_idx: The index of the dataloader that produced this batch.\n        (only if multiple dataloaders used)</p>\n\n<p>Return:\n    - <code>~torch.Tensor</code> - The loss tensor\n    - <code>dict</code> - A dictionary which can include any keys, but must include the key <code>'loss'</code> in the case of\n      automatic optimization.\n    - <code>None</code> - In automatic optimization, this will skip to the next batch (but is not supported for\n      multi-GPU, TPU, or DeepSpeed). For manual optimization, this has no special meaning, as returning\n      the loss is not required.</p>\n\n<p>In this step you'd normally do the forward pass and calculate the loss for a batch.\nYou can also do fancier things like multiple forward passes or something model specific.</p>\n\n<p>Example::</p>\n\n<pre><code>def training_step(self, batch, batch_idx):\n    x, y, z = batch\n    out = self.encoder(x)\n    loss = self.loss(out, x)\n    return loss\n</code></pre>\n\n<p>To use multiple optimizers, you can switch to 'manual optimization' and control their stepping:</p>\n\n<div class=\"pdoc-code codehilite\">\n<pre><span></span><code><span class=\"k\">def</span><span class=\"w\"> </span><span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n    <span class=\"nb\">super</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">()</span>\n    <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">automatic_optimization</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>\n\n\n<span class=\"c1\"># Multiple optimizers (e.g.: GANs)</span>\n<span class=\"k\">def</span><span class=\"w\"> </span><span class=\"nf\">training_step</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">batch</span><span class=\"p\">,</span> <span class=\"n\">batch_idx</span><span class=\"p\">):</span>\n    <span class=\"n\">opt1</span><span class=\"p\">,</span> <span class=\"n\">opt2</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">optimizers</span><span class=\"p\">()</span>\n\n    <span class=\"c1\"># do training_step with encoder</span>\n    <span class=\"o\">...</span>\n    <span class=\"n\">opt1</span><span class=\"o\">.</span><span class=\"n\">step</span><span class=\"p\">()</span>\n    <span class=\"c1\"># do training_step with decoder</span>\n    <span class=\"o\">...</span>\n    <span class=\"n\">opt2</span><span class=\"o\">.</span><span class=\"n\">step</span><span class=\"p\">()</span>\n</code></pre>\n</div>\n\n<p>Note:\n    When <code>accumulate_grad_batches</code> &gt; 1, the loss returned here will be automatically\n    normalized by <code>accumulate_grad_batches</code> internally.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">batch</span>, </span><span class=\"param\"><span class=\"n\">batch_idx</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "my_projects.modeling.train.VGGNet.validation_step", "modulename": "my_projects.modeling.train", "qualname": "VGGNet.validation_step", "kind": "function", "doc": "<p>Operates on a single batch of data from the validation set. In this step you'd might generate examples or\ncalculate anything of interest like accuracy.</p>\n\n<p>Args:\n    batch: The output of your data iterable, normally a <code>~torch.utils.data.DataLoader</code>.\n    batch_idx: The index of this batch.\n    dataloader_idx: The index of the dataloader that produced this batch.\n        (only if multiple dataloaders used)</p>\n\n<p>Return:\n    - <code>~torch.Tensor</code> - The loss tensor\n    - <code>dict</code> - A dictionary. Can include any keys, but must include the key <code>'loss'</code>.\n    - <code>None</code> - Skip to the next batch.</p>\n\n<div class=\"pdoc-code codehilite\">\n<pre><span></span><code><span class=\"c1\"># if you have one val dataloader:</span>\n<span class=\"k\">def</span><span class=\"w\"> </span><span class=\"nf\">validation_step</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">batch</span><span class=\"p\">,</span> <span class=\"n\">batch_idx</span><span class=\"p\">):</span> <span class=\"o\">...</span>\n\n\n<span class=\"c1\"># if you have multiple val dataloaders:</span>\n<span class=\"k\">def</span><span class=\"w\"> </span><span class=\"nf\">validation_step</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">batch</span><span class=\"p\">,</span> <span class=\"n\">batch_idx</span><span class=\"p\">,</span> <span class=\"n\">dataloader_idx</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">):</span> <span class=\"o\">...</span>\n</code></pre>\n</div>\n\n<p>Examples::</p>\n\n<pre><code># CASE 1: A single validation dataset\ndef validation_step(self, batch, batch_idx):\n    x, y = batch\n\n    # implement your own\n    out = self(x)\n    loss = self.loss(out, y)\n\n    # log 6 example images\n    # or generated text... or whatever\n    sample_imgs = x[:6]\n    grid = torchvision.utils.make_grid(sample_imgs)\n    self.logger.experiment.add_image('example_images', grid, 0)\n\n    # calculate acc\n    labels_hat = torch.argmax(out, dim=1)\n    val_acc = torch.sum(y == labels_hat).item() / (len(y) * 1.0)\n\n    # log the outputs!\n    self.log_dict({'val_loss': loss, 'val_acc': val_acc})\n</code></pre>\n\n<p>If you pass in multiple val dataloaders, <code>validation_step()</code> will have an additional argument. We recommend\nsetting the default value of 0 so that you can quickly switch between single and multiple dataloaders.</p>\n\n<div class=\"pdoc-code codehilite\">\n<pre><span></span><code><span class=\"c1\"># CASE 2: multiple validation dataloaders</span>\n<span class=\"k\">def</span><span class=\"w\"> </span><span class=\"nf\">validation_step</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">batch</span><span class=\"p\">,</span> <span class=\"n\">batch_idx</span><span class=\"p\">,</span> <span class=\"n\">dataloader_idx</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">):</span>\n    <span class=\"c1\"># dataloader_idx tells you which dataset this is.</span>\n    <span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">batch</span>\n\n    <span class=\"c1\"># implement your own</span>\n    <span class=\"n\">out</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n\n    <span class=\"k\">if</span> <span class=\"n\">dataloader_idx</span> <span class=\"o\">==</span> <span class=\"mi\">0</span><span class=\"p\">:</span>\n        <span class=\"n\">loss</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">loss0</span><span class=\"p\">(</span><span class=\"n\">out</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">)</span>\n    <span class=\"k\">else</span><span class=\"p\">:</span>\n        <span class=\"n\">loss</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">loss1</span><span class=\"p\">(</span><span class=\"n\">out</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">)</span>\n\n    <span class=\"c1\"># calculate acc</span>\n    <span class=\"n\">labels_hat</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">argmax</span><span class=\"p\">(</span><span class=\"n\">out</span><span class=\"p\">,</span> <span class=\"n\">dim</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n    <span class=\"n\">acc</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">sum</span><span class=\"p\">(</span><span class=\"n\">y</span> <span class=\"o\">==</span> <span class=\"n\">labels_hat</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">item</span><span class=\"p\">()</span> <span class=\"o\">/</span> <span class=\"p\">(</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">y</span><span class=\"p\">)</span> <span class=\"o\">*</span> <span class=\"mf\">1.0</span><span class=\"p\">)</span>\n\n    <span class=\"c1\"># log the outputs separately for each dataloader</span>\n    <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">log_dict</span><span class=\"p\">({</span><span class=\"sa\">f</span><span class=\"s2\">&quot;val_loss_</span><span class=\"si\">{</span><span class=\"n\">dataloader_idx</span><span class=\"si\">}</span><span class=\"s2\">&quot;</span><span class=\"p\">:</span> <span class=\"n\">loss</span><span class=\"p\">,</span> <span class=\"sa\">f</span><span class=\"s2\">&quot;val_acc_</span><span class=\"si\">{</span><span class=\"n\">dataloader_idx</span><span class=\"si\">}</span><span class=\"s2\">&quot;</span><span class=\"p\">:</span> <span class=\"n\">acc</span><span class=\"p\">})</span>\n</code></pre>\n</div>\n\n<p>Note:\n    If you don't need to validate you don't need to implement this method.</p>\n\n<p>Note:\n    When the <code>validation_step()</code> is called, the model has been put in eval mode\n    and PyTorch gradients have been disabled. At the end of validation,\n    the model goes back to training mode and gradients are enabled.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">batch</span>, </span><span class=\"param\"><span class=\"n\">batch_idx</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "my_projects.modeling.train.VGGNet.test_step", "modulename": "my_projects.modeling.train", "qualname": "VGGNet.test_step", "kind": "function", "doc": "<p>Operates on a single batch of data from the test set. In this step you'd normally generate examples or\ncalculate anything of interest such as accuracy.</p>\n\n<p>Args:\n    batch: The output of your data iterable, normally a <code>~torch.utils.data.DataLoader</code>.\n    batch_idx: The index of this batch.\n    dataloader_idx: The index of the dataloader that produced this batch.\n        (only if multiple dataloaders used)</p>\n\n<p>Return:\n    - <code>~torch.Tensor</code> - The loss tensor\n    - <code>dict</code> - A dictionary. Can include any keys, but must include the key <code>'loss'</code>.\n    - <code>None</code> - Skip to the next batch.</p>\n\n<div class=\"pdoc-code codehilite\">\n<pre><span></span><code><span class=\"c1\"># if you have one test dataloader:</span>\n<span class=\"k\">def</span><span class=\"w\"> </span><span class=\"nf\">test_step</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">batch</span><span class=\"p\">,</span> <span class=\"n\">batch_idx</span><span class=\"p\">):</span> <span class=\"o\">...</span>\n\n\n<span class=\"c1\"># if you have multiple test dataloaders:</span>\n<span class=\"k\">def</span><span class=\"w\"> </span><span class=\"nf\">test_step</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">batch</span><span class=\"p\">,</span> <span class=\"n\">batch_idx</span><span class=\"p\">,</span> <span class=\"n\">dataloader_idx</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">):</span> <span class=\"o\">...</span>\n</code></pre>\n</div>\n\n<p>Examples::</p>\n\n<pre><code># CASE 1: A single test dataset\ndef test_step(self, batch, batch_idx):\n    x, y = batch\n\n    # implement your own\n    out = self(x)\n    loss = self.loss(out, y)\n\n    # log 6 example images\n    # or generated text... or whatever\n    sample_imgs = x[:6]\n    grid = torchvision.utils.make_grid(sample_imgs)\n    self.logger.experiment.add_image('example_images', grid, 0)\n\n    # calculate acc\n    labels_hat = torch.argmax(out, dim=1)\n    test_acc = torch.sum(y == labels_hat).item() / (len(y) * 1.0)\n\n    # log the outputs!\n    self.log_dict({'test_loss': loss, 'test_acc': test_acc})\n</code></pre>\n\n<p>If you pass in multiple test dataloaders, <code>test_step()</code> will have an additional argument. We recommend\nsetting the default value of 0 so that you can quickly switch between single and multiple dataloaders.</p>\n\n<div class=\"pdoc-code codehilite\">\n<pre><span></span><code><span class=\"c1\"># CASE 2: multiple test dataloaders</span>\n<span class=\"k\">def</span><span class=\"w\"> </span><span class=\"nf\">test_step</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">batch</span><span class=\"p\">,</span> <span class=\"n\">batch_idx</span><span class=\"p\">,</span> <span class=\"n\">dataloader_idx</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">):</span>\n    <span class=\"c1\"># dataloader_idx tells you which dataset this is.</span>\n    <span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">batch</span>\n\n    <span class=\"c1\"># implement your own</span>\n    <span class=\"n\">out</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n\n    <span class=\"k\">if</span> <span class=\"n\">dataloader_idx</span> <span class=\"o\">==</span> <span class=\"mi\">0</span><span class=\"p\">:</span>\n        <span class=\"n\">loss</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">loss0</span><span class=\"p\">(</span><span class=\"n\">out</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">)</span>\n    <span class=\"k\">else</span><span class=\"p\">:</span>\n        <span class=\"n\">loss</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">loss1</span><span class=\"p\">(</span><span class=\"n\">out</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">)</span>\n\n    <span class=\"c1\"># calculate acc</span>\n    <span class=\"n\">labels_hat</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">argmax</span><span class=\"p\">(</span><span class=\"n\">out</span><span class=\"p\">,</span> <span class=\"n\">dim</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n    <span class=\"n\">acc</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">sum</span><span class=\"p\">(</span><span class=\"n\">y</span> <span class=\"o\">==</span> <span class=\"n\">labels_hat</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">item</span><span class=\"p\">()</span> <span class=\"o\">/</span> <span class=\"p\">(</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">y</span><span class=\"p\">)</span> <span class=\"o\">*</span> <span class=\"mf\">1.0</span><span class=\"p\">)</span>\n\n    <span class=\"c1\"># log the outputs separately for each dataloader</span>\n    <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">log_dict</span><span class=\"p\">({</span><span class=\"sa\">f</span><span class=\"s2\">&quot;test_loss_</span><span class=\"si\">{</span><span class=\"n\">dataloader_idx</span><span class=\"si\">}</span><span class=\"s2\">&quot;</span><span class=\"p\">:</span> <span class=\"n\">loss</span><span class=\"p\">,</span> <span class=\"sa\">f</span><span class=\"s2\">&quot;test_acc_</span><span class=\"si\">{</span><span class=\"n\">dataloader_idx</span><span class=\"si\">}</span><span class=\"s2\">&quot;</span><span class=\"p\">:</span> <span class=\"n\">acc</span><span class=\"p\">})</span>\n</code></pre>\n</div>\n\n<p>Note:\n    If you don't need to test you don't need to implement this method.</p>\n\n<p>Note:\n    When the <code>test_step()</code> is called, the model has been put in eval mode and\n    PyTorch gradients have been disabled. At the end of the test epoch, the model goes back\n    to training mode and gradients are enabled.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">batch</span>, </span><span class=\"param\"><span class=\"n\">batch_idx</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "my_projects.modeling.train.VGGNet.configure_optimizers", "modulename": "my_projects.modeling.train", "qualname": "VGGNet.configure_optimizers", "kind": "function", "doc": "<p>Choose what optimizers and learning-rate schedulers to use in your optimization. Normally you'd need one.\nBut in the case of GANs or similar you might have multiple. Optimization with multiple optimizers only works in\nthe manual optimization mode.</p>\n\n<p>Return:\n    Any of these 6 options.</p>\n\n<pre><code>- **Single optimizer**.\n- **List or Tuple** of optimizers.\n- **Two lists** - The first list has multiple optimizers, and the second has multiple LR schedulers\n  (or multiple ``lr_scheduler_config``).\n- **Dictionary**, with an ``\"optimizer\"`` key, and (optionally) a ``\"lr_scheduler\"``\n  key whose value is a single LR scheduler or ``lr_scheduler_config``.\n- **None** - Fit will run without any optimizer.\n</code></pre>\n\n<p>The <code>lr_scheduler_config</code> is a dictionary which contains the scheduler and its associated configuration.\nThe default configuration is shown below.</p>\n\n<div class=\"pdoc-code codehilite\">\n<pre><span></span><code><span class=\"n\">lr_scheduler_config</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"c1\"># REQUIRED: The scheduler instance</span>\n    <span class=\"s2\">&quot;scheduler&quot;</span><span class=\"p\">:</span> <span class=\"n\">lr_scheduler</span><span class=\"p\">,</span>\n    <span class=\"c1\"># The unit of the scheduler&#39;s step size, could also be &#39;step&#39;.</span>\n    <span class=\"c1\"># &#39;epoch&#39; updates the scheduler on epoch end whereas &#39;step&#39;</span>\n    <span class=\"c1\"># updates it after a optimizer update.</span>\n    <span class=\"s2\">&quot;interval&quot;</span><span class=\"p\">:</span> <span class=\"s2\">&quot;epoch&quot;</span><span class=\"p\">,</span>\n    <span class=\"c1\"># How many epochs/steps should pass between calls to</span>\n    <span class=\"c1\"># `scheduler.step()`. 1 corresponds to updating the learning</span>\n    <span class=\"c1\"># rate after every epoch/step.</span>\n    <span class=\"s2\">&quot;frequency&quot;</span><span class=\"p\">:</span> <span class=\"mi\">1</span><span class=\"p\">,</span>\n    <span class=\"c1\"># Metric to monitor for schedulers like `ReduceLROnPlateau`</span>\n    <span class=\"s2\">&quot;monitor&quot;</span><span class=\"p\">:</span> <span class=\"s2\">&quot;val_loss&quot;</span><span class=\"p\">,</span>\n    <span class=\"c1\"># If set to `True`, will enforce that the value specified &#39;monitor&#39;</span>\n    <span class=\"c1\"># is available when the scheduler is updated, thus stopping</span>\n    <span class=\"c1\"># training if not found. If set to `False`, it will only produce a warning</span>\n    <span class=\"s2\">&quot;strict&quot;</span><span class=\"p\">:</span> <span class=\"kc\">True</span><span class=\"p\">,</span>\n    <span class=\"c1\"># If using the `LearningRateMonitor` callback to monitor the</span>\n    <span class=\"c1\"># learning rate progress, this keyword can be used to specify</span>\n    <span class=\"c1\"># a custom logged name</span>\n    <span class=\"s2\">&quot;name&quot;</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</code></pre>\n</div>\n\n<p>When there are schedulers in which the <code>.step()</code> method is conditioned on a value, such as the\n<code>torch.optim.lr_scheduler.ReduceLROnPlateau</code> scheduler, Lightning requires that the\n<code>lr_scheduler_config</code> contains the keyword <code>\"monitor\"</code> set to the metric name that the scheduler\nshould be conditioned on.</p>\n\n<p>.. testcode::</p>\n\n<pre><code># The ReduceLROnPlateau scheduler requires a monitor\ndef configure_optimizers(self):\n    optimizer = Adam(...)\n    return {\n        \"optimizer\": optimizer,\n        \"lr_scheduler\": {\n            \"scheduler\": ReduceLROnPlateau(optimizer, ...),\n            \"monitor\": \"metric_to_track\",\n            \"frequency\": \"indicates how often the metric is updated\",\n            # If \"monitor\" references validation metrics, then \"frequency\" should be set to a\n            # multiple of \"trainer.check_val_every_n_epoch\".\n        },\n    }\n\n\n# In the case of two optimizers, only one using the ReduceLROnPlateau scheduler\ndef configure_optimizers(self):\n    optimizer1 = Adam(...)\n    optimizer2 = SGD(...)\n    scheduler1 = ReduceLROnPlateau(optimizer1, ...)\n    scheduler2 = LambdaLR(optimizer2, ...)\n    return (\n        {\n            \"optimizer\": optimizer1,\n            \"lr_scheduler\": {\n                \"scheduler\": scheduler1,\n                \"monitor\": \"metric_to_track\",\n            },\n        },\n        {\"optimizer\": optimizer2, \"lr_scheduler\": scheduler2},\n    )\n</code></pre>\n\n<p>Metrics can be made available to monitor by simply logging it using\n<code>self.log('metric_to_track', metric_val)</code> in your <code>~pytorch_lightning.core.LightningModule</code>.</p>\n\n<p>Note:\n    Some things to know:</p>\n\n<pre><code>- Lightning calls ``.backward()`` and ``.step()`` automatically in case of automatic optimization.\n- If a learning rate scheduler is specified in ``configure_optimizers()`` with key\n  ``\"interval\"`` (default \"epoch\") in the scheduler configuration, Lightning will call\n  the scheduler's ``.step()`` method automatically in case of automatic optimization.\n- If you use 16-bit precision (``precision=16``), Lightning will automatically handle the optimizer.\n- If you use `torch.optim.LBFGS`, Lightning handles the closure function automatically for you.\n- If you use multiple optimizers, you will have to switch to 'manual optimization' mode and step them\n  yourself.\n- If you need to control how often the optimizer steps, override the `optimizer_step()` hook.\n</code></pre>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "my_projects.modeling.train.GradioProgressCallback", "modulename": "my_projects.modeling.train", "qualname": "GradioProgressCallback", "kind": "class", "doc": "<p>Custom PyTorch Lightning callback to report training progress to the Gradio UI.</p>\n\n<p>This callback hooks into the training loop and updates a Gradio progress bar\nafter every batch, calculating the overall percentage based on the total\nnumber of epochs and batches.</p>\n", "bases": "pytorch_lightning.callbacks.callback.Callback"}, {"fullname": "my_projects.modeling.train.GradioProgressCallback.__init__", "modulename": "my_projects.modeling.train", "qualname": "GradioProgressCallback.__init__", "kind": "function", "doc": "<p>Initializes the callback.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>progress_fn : callable\n    The Gradio progress update function (usually <code>gradio.Progress()</code>).\nmax_epochs : int\n    The total number of epochs to train for. Used to calculate\n    the completion percentage.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">progress_fn</span>, </span><span class=\"param\"><span class=\"n\">max_epochs</span></span>)</span>"}, {"fullname": "my_projects.modeling.train.GradioProgressCallback.progress_fn", "modulename": "my_projects.modeling.train", "qualname": "GradioProgressCallback.progress_fn", "kind": "variable", "doc": "<p>Gradio function to update the UI progress bar.</p>\n"}, {"fullname": "my_projects.modeling.train.GradioProgressCallback.max_epochs", "modulename": "my_projects.modeling.train", "qualname": "GradioProgressCallback.max_epochs", "kind": "variable", "doc": "<p>Total number of epochs scheduled for training.</p>\n"}, {"fullname": "my_projects.modeling.train.GradioProgressCallback.total_batches", "modulename": "my_projects.modeling.train", "qualname": "GradioProgressCallback.total_batches", "kind": "variable", "doc": "<p>Cached number of batches per epoch (lazy-loaded).</p>\n"}, {"fullname": "my_projects.modeling.train.GradioProgressCallback.on_train_batch_end", "modulename": "my_projects.modeling.train", "qualname": "GradioProgressCallback.on_train_batch_end", "kind": "function", "doc": "<p>Updates the Gradio progress bar at the end of each training batch.</p>\n\n<p>Calculates the global step count and updates the progress percentage\nand description string in the UI.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>trainer : pl.Trainer\n    The PyTorch Lightning trainer instance.\npl_module : pl.LightningModule\n    The model being trained.\noutputs : dict\n    The outputs of the training step.\nbatch : Any\n    The current batch of data.\nbatch_idx : int\n    The index of the current batch.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">trainer</span>, </span><span class=\"param\"><span class=\"n\">pl_module</span>, </span><span class=\"param\"><span class=\"n\">outputs</span>, </span><span class=\"param\"><span class=\"n\">batch</span>, </span><span class=\"param\"><span class=\"n\">batch_idx</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "my_projects.modeling.train.main", "modulename": "my_projects.modeling.train", "qualname": "main", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">architecture</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;vgg16&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">dataset_choice</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;mini&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">seed</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">42</span>,</span><span class=\"param\">\t<span class=\"n\">test_frac</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.2</span>,</span><span class=\"param\">\t<span class=\"n\">max_epochs</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">5</span>,</span><span class=\"param\">\t<span class=\"n\">batch_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">16</span>,</span><span class=\"param\">\t<span class=\"n\">num_workers</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">2</span>,</span><span class=\"param\">\t<span class=\"n\">is_demo</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">progress</span><span class=\"p\">:</span> <span class=\"n\">gradio</span><span class=\"o\">.</span><span class=\"n\">helpers</span><span class=\"o\">.</span><span class=\"n\">Progress</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "my_projects.plots", "modulename": "my_projects.plots", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "my_projects.plots.get_category_images", "modulename": "my_projects.plots", "qualname": "get_category_images", "kind": "function", "doc": "<p>Retrieves the list of images for a specific category.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>category_path : str or Path\n        The path to the category folder.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>list of str\n        A list containing the filenames of valid images \n        (.jpg, .jpeg, .png, .bmp, .gif) within the folder.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">category_path</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "my_projects.plots.get_category_names", "modulename": "my_projects.plots", "qualname": "get_category_names", "kind": "function", "doc": "<p>Reads the category names from a text file.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>data_dir : Path\n        Path to the directory containing the 'name of the animals.txt' file.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>list of str\n        A list of category names (one per line in the file).</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">data_dir</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "my_projects.plots.calculate_rgb_averages", "modulename": "my_projects.plots", "qualname": "calculate_rgb_averages", "kind": "function", "doc": "<p>Calculates the average R, G, and B values per image category.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>data_dir : Path\n        Path to the data directory containing the images within 'mini_animals'.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>dict\n        A dictionary with categories as keys and the [R, G, B] averages as values.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">data_dir</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "my_projects.plots.plot_rgb_heatmap", "modulename": "my_projects.plots", "qualname": "plot_rgb_heatmap", "kind": "function", "doc": "<p>Generates a heatmap of average R, G, B values per class.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>df : pandas.DataFrame\n    DataFrame with columns ['R', 'G', 'B', 'luminance'].\npath : Path\n    Path where the figure will be saved.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">df</span>, </span><span class=\"param\"><span class=\"n\">path</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "my_projects.plots.plot_clustermap", "modulename": "my_projects.plots", "qualname": "plot_clustermap", "kind": "function", "doc": "<p>Generates a hierarchical clustermap of R, G, and B values.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>df : pandas.DataFrame\n    DataFrame with normalized ['R', 'G', 'B'] columns.\npath : Path\n    Path where the figure will be saved.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">df</span>, </span><span class=\"param\"><span class=\"n\">path</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "my_projects.plots.plot_avg_colors", "modulename": "my_projects.plots", "qualname": "plot_avg_colors", "kind": "function", "doc": "<p>Generates a visualization of the average colors per class.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>df : pandas.DataFrame\n    DataFrame with columns ['class', 'R', 'G', 'B'].\npath : Path\n    Path where the figure will be saved.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">df</span>, </span><span class=\"param\"><span class=\"n\">path</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "my_projects.plots.get_df_with_rgb_avg", "modulename": "my_projects.plots", "qualname": "get_df_with_rgb_avg", "kind": "function", "doc": "<p>Converts a dictionary of RGB averages into a DataFrame and adds metrics.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>medias_rgb : dict\n    Dictionary with categories as keys and average [R, G, B] values.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>pandas.DataFrame\n    DataFrame with columns:\n    - 'class': The class name.\n    - 'R', 'G', 'B': Normalized values (0.0-1.0).\n    - 'luminance': Perceptual luminance.\n    - 'colorfulness': An approximate colorfulness metric.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">medias_rgb</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "my_projects.reduce_data", "modulename": "my_projects.reduce_data", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "my_projects.reduce_data.reduce_dataset", "modulename": "my_projects.reduce_data", "qualname": "reduce_dataset", "kind": "function", "doc": "<p>Reduces an image dataset by sampling and resizing images.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>data_dir : str or Path\n    Path to the original, full dataset directory (e.g., 'data/animals').\noutput_dir : str or Path\n    Path to the directory where the reduced dataset will be saved \n    (e.g., 'data/mini_animals').\nimages_per_class : int\n    The exact number of images to sample from each class.\nimage_size : int\n    The target size (width and height) for resizing (e.g., 224).\nprogress : callable, optional\n    An optional callback function for reporting progress (e.g., for a\n    Gradio or Streamlit GUI). It should accept <code>(float, desc=str)</code>.\nseed : int, optional\n    A random seed to ensure reproducible sampling (default is 123).</p>\n\n<h2 id=\"raises\">Raises</h2>\n\n<p>ValueError\n    If a class folder is found to contain fewer images than\n    the requested <code>images_per_class</code>.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">data_dir</span>,</span><span class=\"param\">\t<span class=\"n\">output_dir</span>,</span><span class=\"param\">\t<span class=\"n\">images_per_class</span>,</span><span class=\"param\">\t<span class=\"n\">image_size</span>,</span><span class=\"param\">\t<span class=\"n\">progress</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">seed</span><span class=\"o\">=</span><span class=\"mi\">123</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "my_projects.scripts", "modulename": "my_projects.scripts", "kind": "module", "doc": "<h1 id=\"scripts-package-my_projectsscripts\">Scripts Package (my_projects.scripts)</h1>\n\n<p>This package contains auxiliary scripts and utilities for the project,\nsuch as launching web applications or batch processes.</p>\n\n<p>Available Submodules:</p>\n\n<ul>\n<li><strong>dashboard</strong>: Contains the code for the interactive dashboard.</li>\n</ul>\n"}, {"fullname": "my_projects.scripts.dashboard", "modulename": "my_projects.scripts.dashboard", "kind": "module", "doc": "<p>Gradio Interface for the Animal Classification Project.</p>\n\n<p>This script creates an interactive web dashboard using Gradio to run\nthe project's three main workflows:</p>\n\n<ol>\n<li>Data Reduction (creating the 'mini_animals' dataset).</li>\n<li>Model Training (VGG16, VGG11).</li>\n<li>Inference and metric visualization (Confusion Matrix, ROC, etc.).</li>\n</ol>\n"}, {"fullname": "my_projects.scripts.dashboard.PROJECT_ROOT", "modulename": "my_projects.scripts.dashboard", "qualname": "PROJECT_ROOT", "kind": "variable", "doc": "<p>Dynamically calculated project root path.</p>\n", "default_value": "PosixPath(&#x27;/home/alumno/Desktop/Master/Software_Project/animal-classification&#x27;)"}, {"fullname": "my_projects.scripts.dashboard.DATA_DIR", "modulename": "my_projects.scripts.dashboard", "qualname": "DATA_DIR", "kind": "variable", "doc": "<p>Directory where the reduced dataset is stored.</p>\n", "default_value": "PosixPath(&#x27;/home/alumno/Desktop/Master/Software_Project/animal-classification/data/mini_animals/animals&#x27;)"}, {"fullname": "my_projects.scripts.dashboard.VGG11", "modulename": "my_projects.scripts.dashboard", "qualname": "VGG11", "kind": "variable", "doc": "<p>Placeholder for the VGG11 model.</p>\n", "default_value": "None"}, {"fullname": "my_projects.scripts.dashboard.VGG16", "modulename": "my_projects.scripts.dashboard", "qualname": "VGG16", "kind": "variable", "doc": "<p>Placeholder for the VGG16 model.</p>\n", "default_value": "None"}, {"fullname": "my_projects.scripts.dashboard.run_training", "modulename": "my_projects.scripts.dashboard", "qualname": "run_training", "kind": "function", "doc": "<p>Runs the model training script and returns metrics.</p>\n\n<p>Gradio wrapper for the <code>train_main</code> function.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>model_choice : str\n    Model architecture to train (e.g., \"VGG16\").\nseed : int or float\n    Random seed for reproducibility. Will be cast to int.\nepochs : int or float\n    Maximum number of epochs. Will be cast to int.\nnum_workers : int\n    Number of subprocesses to use for data loading.\nprogress : gradio.Progress, optional\n    Gradio object to track training progress.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>None\n    A placeholder for the plot output (currently unused).\nstr\n    A formatted string with performance metrics (Test Accuracy).\nstr\n    A simple status message indicating completion.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">model_choice</span>,</span><span class=\"param\">\t<span class=\"n\">seed</span>,</span><span class=\"param\">\t<span class=\"n\">epochs</span>,</span><span class=\"param\">\t<span class=\"n\">num_workers</span>,</span><span class=\"param\">\t<span class=\"n\">progress</span><span class=\"o\">=&lt;</span><span class=\"n\">gradio</span><span class=\"o\">.</span><span class=\"n\">helpers</span><span class=\"o\">.</span><span class=\"n\">Progress</span> <span class=\"nb\">object</span><span class=\"o\">&gt;</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "my_projects.scripts.dashboard.run_inference_gr", "modulename": "my_projects.scripts.dashboard", "qualname": "run_inference_gr", "kind": "function", "doc": "<p>Runs inference on the validation set and generates visualizations.</p>\n\n<p>If a trained_model is provided (from demo memory), it is used directly.\nOtherwise, the function loads a model checkpoint from disk.</p>\n\n<p>Metrics are displayed in the dashboard but not stored on disk.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">trained_model</span>, </span><span class=\"param\"><span class=\"n\">batch_size</span>, </span><span class=\"param\"><span class=\"n\">num_workers</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "my_projects.scripts.dashboard.dark_theme", "modulename": "my_projects.scripts.dashboard", "qualname": "dark_theme", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;gradio.themes.monochrome.Monochrome object&gt;"}, {"fullname": "my_projects.scripts.dashboard.main", "modulename": "my_projects.scripts.dashboard", "qualname": "main", "kind": "function", "doc": "<p>Launches the Gradio web application.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}];

    // mirrored in build-search-index.js (part 1)
    // Also split on html tags. this is a cheap heuristic, but good enough.
    elasticlunr.tokenizer.setSeperator(/[\s\-.;&_'"=,()]+|<[^>]*>/);

    let searchIndex;
    if (docs._isPrebuiltIndex) {
        console.info("using precompiled search index");
        searchIndex = elasticlunr.Index.load(docs);
    } else {
        console.time("building search index");
        // mirrored in build-search-index.js (part 2)
        searchIndex = elasticlunr(function () {
            this.pipeline.remove(elasticlunr.stemmer);
            this.pipeline.remove(elasticlunr.stopWordFilter);
            this.addField("qualname");
            this.addField("fullname");
            this.addField("annotation");
            this.addField("default_value");
            this.addField("signature");
            this.addField("bases");
            this.addField("doc");
            this.setRef("fullname");
        });
        for (let doc of docs) {
            searchIndex.addDoc(doc);
        }
        console.timeEnd("building search index");
    }

    return (term) => searchIndex.search(term, {
        fields: {
            qualname: {boost: 4},
            fullname: {boost: 2},
            annotation: {boost: 2},
            default_value: {boost: 2},
            signature: {boost: 2},
            bases: {boost: 2},
            doc: {boost: 1},
        },
        expand: true
    });
})();