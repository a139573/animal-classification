window.pdocSearch = (function(){
/** elasticlunr - http://weixsong.github.io * Copyright (C) 2017 Oliver Nightingale * Copyright (C) 2017 Wei Song * MIT Licensed */!function(){function e(e){if(null===e||"object"!=typeof e)return e;var t=e.constructor();for(var n in e)e.hasOwnProperty(n)&&(t[n]=e[n]);return t}var t=function(e){var n=new t.Index;return n.pipeline.add(t.trimmer,t.stopWordFilter,t.stemmer),e&&e.call(n,n),n};t.version="0.9.5",lunr=t,t.utils={},t.utils.warn=function(e){return function(t){e.console&&console.warn&&console.warn(t)}}(this),t.utils.toString=function(e){return void 0===e||null===e?"":e.toString()},t.EventEmitter=function(){this.events={}},t.EventEmitter.prototype.addListener=function(){var e=Array.prototype.slice.call(arguments),t=e.pop(),n=e;if("function"!=typeof t)throw new TypeError("last argument must be a function");n.forEach(function(e){this.hasHandler(e)||(this.events[e]=[]),this.events[e].push(t)},this)},t.EventEmitter.prototype.removeListener=function(e,t){if(this.hasHandler(e)){var n=this.events[e].indexOf(t);-1!==n&&(this.events[e].splice(n,1),0==this.events[e].length&&delete this.events[e])}},t.EventEmitter.prototype.emit=function(e){if(this.hasHandler(e)){var t=Array.prototype.slice.call(arguments,1);this.events[e].forEach(function(e){e.apply(void 0,t)},this)}},t.EventEmitter.prototype.hasHandler=function(e){return e in this.events},t.tokenizer=function(e){if(!arguments.length||null===e||void 0===e)return[];if(Array.isArray(e)){var n=e.filter(function(e){return null===e||void 0===e?!1:!0});n=n.map(function(e){return t.utils.toString(e).toLowerCase()});var i=[];return n.forEach(function(e){var n=e.split(t.tokenizer.seperator);i=i.concat(n)},this),i}return e.toString().trim().toLowerCase().split(t.tokenizer.seperator)},t.tokenizer.defaultSeperator=/[\s\-]+/,t.tokenizer.seperator=t.tokenizer.defaultSeperator,t.tokenizer.setSeperator=function(e){null!==e&&void 0!==e&&"object"==typeof e&&(t.tokenizer.seperator=e)},t.tokenizer.resetSeperator=function(){t.tokenizer.seperator=t.tokenizer.defaultSeperator},t.tokenizer.getSeperator=function(){return t.tokenizer.seperator},t.Pipeline=function(){this._queue=[]},t.Pipeline.registeredFunctions={},t.Pipeline.registerFunction=function(e,n){n in t.Pipeline.registeredFunctions&&t.utils.warn("Overwriting existing registered function: "+n),e.label=n,t.Pipeline.registeredFunctions[n]=e},t.Pipeline.getRegisteredFunction=function(e){return e in t.Pipeline.registeredFunctions!=!0?null:t.Pipeline.registeredFunctions[e]},t.Pipeline.warnIfFunctionNotRegistered=function(e){var n=e.label&&e.label in this.registeredFunctions;n||t.utils.warn("Function is not registered with pipeline. This may cause problems when serialising the index.\n",e)},t.Pipeline.load=function(e){var n=new t.Pipeline;return e.forEach(function(e){var i=t.Pipeline.getRegisteredFunction(e);if(!i)throw new Error("Cannot load un-registered function: "+e);n.add(i)}),n},t.Pipeline.prototype.add=function(){var e=Array.prototype.slice.call(arguments);e.forEach(function(e){t.Pipeline.warnIfFunctionNotRegistered(e),this._queue.push(e)},this)},t.Pipeline.prototype.after=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i+1,0,n)},t.Pipeline.prototype.before=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i,0,n)},t.Pipeline.prototype.remove=function(e){var t=this._queue.indexOf(e);-1!==t&&this._queue.splice(t,1)},t.Pipeline.prototype.run=function(e){for(var t=[],n=e.length,i=this._queue.length,o=0;n>o;o++){for(var r=e[o],s=0;i>s&&(r=this._queue[s](r,o,e),void 0!==r&&null!==r);s++);void 0!==r&&null!==r&&t.push(r)}return t},t.Pipeline.prototype.reset=function(){this._queue=[]},t.Pipeline.prototype.get=function(){return this._queue},t.Pipeline.prototype.toJSON=function(){return this._queue.map(function(e){return t.Pipeline.warnIfFunctionNotRegistered(e),e.label})},t.Index=function(){this._fields=[],this._ref="id",this.pipeline=new t.Pipeline,this.documentStore=new t.DocumentStore,this.index={},this.eventEmitter=new t.EventEmitter,this._idfCache={},this.on("add","remove","update",function(){this._idfCache={}}.bind(this))},t.Index.prototype.on=function(){var e=Array.prototype.slice.call(arguments);return this.eventEmitter.addListener.apply(this.eventEmitter,e)},t.Index.prototype.off=function(e,t){return this.eventEmitter.removeListener(e,t)},t.Index.load=function(e){e.version!==t.version&&t.utils.warn("version mismatch: current "+t.version+" importing "+e.version);var n=new this;n._fields=e.fields,n._ref=e.ref,n.documentStore=t.DocumentStore.load(e.documentStore),n.pipeline=t.Pipeline.load(e.pipeline),n.index={};for(var i in e.index)n.index[i]=t.InvertedIndex.load(e.index[i]);return n},t.Index.prototype.addField=function(e){return this._fields.push(e),this.index[e]=new t.InvertedIndex,this},t.Index.prototype.setRef=function(e){return this._ref=e,this},t.Index.prototype.saveDocument=function(e){return this.documentStore=new t.DocumentStore(e),this},t.Index.prototype.addDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.addDoc(i,e),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));this.documentStore.addFieldLength(i,n,o.length);var r={};o.forEach(function(e){e in r?r[e]+=1:r[e]=1},this);for(var s in r){var u=r[s];u=Math.sqrt(u),this.index[n].addToken(s,{ref:i,tf:u})}},this),n&&this.eventEmitter.emit("add",e,this)}},t.Index.prototype.removeDocByRef=function(e){if(e&&this.documentStore.isDocStored()!==!1&&this.documentStore.hasDoc(e)){var t=this.documentStore.getDoc(e);this.removeDoc(t,!1)}},t.Index.prototype.removeDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.hasDoc(i)&&(this.documentStore.removeDoc(i),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));o.forEach(function(e){this.index[n].removeToken(e,i)},this)},this),n&&this.eventEmitter.emit("remove",e,this))}},t.Index.prototype.updateDoc=function(e,t){var t=void 0===t?!0:t;this.removeDocByRef(e[this._ref],!1),this.addDoc(e,!1),t&&this.eventEmitter.emit("update",e,this)},t.Index.prototype.idf=function(e,t){var n="@"+t+"/"+e;if(Object.prototype.hasOwnProperty.call(this._idfCache,n))return this._idfCache[n];var i=this.index[t].getDocFreq(e),o=1+Math.log(this.documentStore.length/(i+1));return this._idfCache[n]=o,o},t.Index.prototype.getFields=function(){return this._fields.slice()},t.Index.prototype.search=function(e,n){if(!e)return[];e="string"==typeof e?{any:e}:JSON.parse(JSON.stringify(e));var i=null;null!=n&&(i=JSON.stringify(n));for(var o=new t.Configuration(i,this.getFields()).get(),r={},s=Object.keys(e),u=0;u<s.length;u++){var a=s[u];r[a]=this.pipeline.run(t.tokenizer(e[a]))}var l={};for(var c in o){var d=r[c]||r.any;if(d){var f=this.fieldSearch(d,c,o),h=o[c].boost;for(var p in f)f[p]=f[p]*h;for(var p in f)p in l?l[p]+=f[p]:l[p]=f[p]}}var v,g=[];for(var p in l)v={ref:p,score:l[p]},this.documentStore.hasDoc(p)&&(v.doc=this.documentStore.getDoc(p)),g.push(v);return g.sort(function(e,t){return t.score-e.score}),g},t.Index.prototype.fieldSearch=function(e,t,n){var i=n[t].bool,o=n[t].expand,r=n[t].boost,s=null,u={};return 0!==r?(e.forEach(function(e){var n=[e];1==o&&(n=this.index[t].expandToken(e));var r={};n.forEach(function(n){var o=this.index[t].getDocs(n),a=this.idf(n,t);if(s&&"AND"==i){var l={};for(var c in s)c in o&&(l[c]=o[c]);o=l}n==e&&this.fieldSearchStats(u,n,o);for(var c in o){var d=this.index[t].getTermFrequency(n,c),f=this.documentStore.getFieldLength(c,t),h=1;0!=f&&(h=1/Math.sqrt(f));var p=1;n!=e&&(p=.15*(1-(n.length-e.length)/n.length));var v=d*a*h*p;c in r?r[c]+=v:r[c]=v}},this),s=this.mergeScores(s,r,i)},this),s=this.coordNorm(s,u,e.length)):void 0},t.Index.prototype.mergeScores=function(e,t,n){if(!e)return t;if("AND"==n){var i={};for(var o in t)o in e&&(i[o]=e[o]+t[o]);return i}for(var o in t)o in e?e[o]+=t[o]:e[o]=t[o];return e},t.Index.prototype.fieldSearchStats=function(e,t,n){for(var i in n)i in e?e[i].push(t):e[i]=[t]},t.Index.prototype.coordNorm=function(e,t,n){for(var i in e)if(i in t){var o=t[i].length;e[i]=e[i]*o/n}return e},t.Index.prototype.toJSON=function(){var e={};return this._fields.forEach(function(t){e[t]=this.index[t].toJSON()},this),{version:t.version,fields:this._fields,ref:this._ref,documentStore:this.documentStore.toJSON(),index:e,pipeline:this.pipeline.toJSON()}},t.Index.prototype.use=function(e){var t=Array.prototype.slice.call(arguments,1);t.unshift(this),e.apply(this,t)},t.DocumentStore=function(e){this._save=null===e||void 0===e?!0:e,this.docs={},this.docInfo={},this.length=0},t.DocumentStore.load=function(e){var t=new this;return t.length=e.length,t.docs=e.docs,t.docInfo=e.docInfo,t._save=e.save,t},t.DocumentStore.prototype.isDocStored=function(){return this._save},t.DocumentStore.prototype.addDoc=function(t,n){this.hasDoc(t)||this.length++,this.docs[t]=this._save===!0?e(n):null},t.DocumentStore.prototype.getDoc=function(e){return this.hasDoc(e)===!1?null:this.docs[e]},t.DocumentStore.prototype.hasDoc=function(e){return e in this.docs},t.DocumentStore.prototype.removeDoc=function(e){this.hasDoc(e)&&(delete this.docs[e],delete this.docInfo[e],this.length--)},t.DocumentStore.prototype.addFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&(this.docInfo[e]||(this.docInfo[e]={}),this.docInfo[e][t]=n)},t.DocumentStore.prototype.updateFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&this.addFieldLength(e,t,n)},t.DocumentStore.prototype.getFieldLength=function(e,t){return null===e||void 0===e?0:e in this.docs&&t in this.docInfo[e]?this.docInfo[e][t]:0},t.DocumentStore.prototype.toJSON=function(){return{docs:this.docs,docInfo:this.docInfo,length:this.length,save:this._save}},t.stemmer=function(){var e={ational:"ate",tional:"tion",enci:"ence",anci:"ance",izer:"ize",bli:"ble",alli:"al",entli:"ent",eli:"e",ousli:"ous",ization:"ize",ation:"ate",ator:"ate",alism:"al",iveness:"ive",fulness:"ful",ousness:"ous",aliti:"al",iviti:"ive",biliti:"ble",logi:"log"},t={icate:"ic",ative:"",alize:"al",iciti:"ic",ical:"ic",ful:"",ness:""},n="[^aeiou]",i="[aeiouy]",o=n+"[^aeiouy]*",r=i+"[aeiou]*",s="^("+o+")?"+r+o,u="^("+o+")?"+r+o+"("+r+")?$",a="^("+o+")?"+r+o+r+o,l="^("+o+")?"+i,c=new RegExp(s),d=new RegExp(a),f=new RegExp(u),h=new RegExp(l),p=/^(.+?)(ss|i)es$/,v=/^(.+?)([^s])s$/,g=/^(.+?)eed$/,m=/^(.+?)(ed|ing)$/,y=/.$/,S=/(at|bl|iz)$/,x=new RegExp("([^aeiouylsz])\\1$"),w=new RegExp("^"+o+i+"[^aeiouwxy]$"),I=/^(.+?[^aeiou])y$/,b=/^(.+?)(ational|tional|enci|anci|izer|bli|alli|entli|eli|ousli|ization|ation|ator|alism|iveness|fulness|ousness|aliti|iviti|biliti|logi)$/,E=/^(.+?)(icate|ative|alize|iciti|ical|ful|ness)$/,D=/^(.+?)(al|ance|ence|er|ic|able|ible|ant|ement|ment|ent|ou|ism|ate|iti|ous|ive|ize)$/,F=/^(.+?)(s|t)(ion)$/,_=/^(.+?)e$/,P=/ll$/,k=new RegExp("^"+o+i+"[^aeiouwxy]$"),z=function(n){var i,o,r,s,u,a,l;if(n.length<3)return n;if(r=n.substr(0,1),"y"==r&&(n=r.toUpperCase()+n.substr(1)),s=p,u=v,s.test(n)?n=n.replace(s,"$1$2"):u.test(n)&&(n=n.replace(u,"$1$2")),s=g,u=m,s.test(n)){var z=s.exec(n);s=c,s.test(z[1])&&(s=y,n=n.replace(s,""))}else if(u.test(n)){var z=u.exec(n);i=z[1],u=h,u.test(i)&&(n=i,u=S,a=x,l=w,u.test(n)?n+="e":a.test(n)?(s=y,n=n.replace(s,"")):l.test(n)&&(n+="e"))}if(s=I,s.test(n)){var z=s.exec(n);i=z[1],n=i+"i"}if(s=b,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+e[o])}if(s=E,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+t[o])}if(s=D,u=F,s.test(n)){var z=s.exec(n);i=z[1],s=d,s.test(i)&&(n=i)}else if(u.test(n)){var z=u.exec(n);i=z[1]+z[2],u=d,u.test(i)&&(n=i)}if(s=_,s.test(n)){var z=s.exec(n);i=z[1],s=d,u=f,a=k,(s.test(i)||u.test(i)&&!a.test(i))&&(n=i)}return s=P,u=d,s.test(n)&&u.test(n)&&(s=y,n=n.replace(s,"")),"y"==r&&(n=r.toLowerCase()+n.substr(1)),n};return z}(),t.Pipeline.registerFunction(t.stemmer,"stemmer"),t.stopWordFilter=function(e){return e&&t.stopWordFilter.stopWords[e]!==!0?e:void 0},t.clearStopWords=function(){t.stopWordFilter.stopWords={}},t.addStopWords=function(e){null!=e&&Array.isArray(e)!==!1&&e.forEach(function(e){t.stopWordFilter.stopWords[e]=!0},this)},t.resetStopWords=function(){t.stopWordFilter.stopWords=t.defaultStopWords},t.defaultStopWords={"":!0,a:!0,able:!0,about:!0,across:!0,after:!0,all:!0,almost:!0,also:!0,am:!0,among:!0,an:!0,and:!0,any:!0,are:!0,as:!0,at:!0,be:!0,because:!0,been:!0,but:!0,by:!0,can:!0,cannot:!0,could:!0,dear:!0,did:!0,"do":!0,does:!0,either:!0,"else":!0,ever:!0,every:!0,"for":!0,from:!0,get:!0,got:!0,had:!0,has:!0,have:!0,he:!0,her:!0,hers:!0,him:!0,his:!0,how:!0,however:!0,i:!0,"if":!0,"in":!0,into:!0,is:!0,it:!0,its:!0,just:!0,least:!0,let:!0,like:!0,likely:!0,may:!0,me:!0,might:!0,most:!0,must:!0,my:!0,neither:!0,no:!0,nor:!0,not:!0,of:!0,off:!0,often:!0,on:!0,only:!0,or:!0,other:!0,our:!0,own:!0,rather:!0,said:!0,say:!0,says:!0,she:!0,should:!0,since:!0,so:!0,some:!0,than:!0,that:!0,the:!0,their:!0,them:!0,then:!0,there:!0,these:!0,they:!0,"this":!0,tis:!0,to:!0,too:!0,twas:!0,us:!0,wants:!0,was:!0,we:!0,were:!0,what:!0,when:!0,where:!0,which:!0,"while":!0,who:!0,whom:!0,why:!0,will:!0,"with":!0,would:!0,yet:!0,you:!0,your:!0},t.stopWordFilter.stopWords=t.defaultStopWords,t.Pipeline.registerFunction(t.stopWordFilter,"stopWordFilter"),t.trimmer=function(e){if(null===e||void 0===e)throw new Error("token should not be undefined");return e.replace(/^\W+/,"").replace(/\W+$/,"")},t.Pipeline.registerFunction(t.trimmer,"trimmer"),t.InvertedIndex=function(){this.root={docs:{},df:0}},t.InvertedIndex.load=function(e){var t=new this;return t.root=e.root,t},t.InvertedIndex.prototype.addToken=function(e,t,n){for(var n=n||this.root,i=0;i<=e.length-1;){var o=e[i];o in n||(n[o]={docs:{},df:0}),i+=1,n=n[o]}var r=t.ref;n.docs[r]?n.docs[r]={tf:t.tf}:(n.docs[r]={tf:t.tf},n.df+=1)},t.InvertedIndex.prototype.hasToken=function(e){if(!e)return!1;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return!1;t=t[e[n]]}return!0},t.InvertedIndex.prototype.getNode=function(e){if(!e)return null;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return null;t=t[e[n]]}return t},t.InvertedIndex.prototype.getDocs=function(e){var t=this.getNode(e);return null==t?{}:t.docs},t.InvertedIndex.prototype.getTermFrequency=function(e,t){var n=this.getNode(e);return null==n?0:t in n.docs?n.docs[t].tf:0},t.InvertedIndex.prototype.getDocFreq=function(e){var t=this.getNode(e);return null==t?0:t.df},t.InvertedIndex.prototype.removeToken=function(e,t){if(e){var n=this.getNode(e);null!=n&&t in n.docs&&(delete n.docs[t],n.df-=1)}},t.InvertedIndex.prototype.expandToken=function(e,t,n){if(null==e||""==e)return[];var t=t||[];if(void 0==n&&(n=this.getNode(e),null==n))return t;n.df>0&&t.push(e);for(var i in n)"docs"!==i&&"df"!==i&&this.expandToken(e+i,t,n[i]);return t},t.InvertedIndex.prototype.toJSON=function(){return{root:this.root}},t.Configuration=function(e,n){var e=e||"";if(void 0==n||null==n)throw new Error("fields should not be null");this.config={};var i;try{i=JSON.parse(e),this.buildUserConfig(i,n)}catch(o){t.utils.warn("user configuration parse failed, will use default configuration"),this.buildDefaultConfig(n)}},t.Configuration.prototype.buildDefaultConfig=function(e){this.reset(),e.forEach(function(e){this.config[e]={boost:1,bool:"OR",expand:!1}},this)},t.Configuration.prototype.buildUserConfig=function(e,n){var i="OR",o=!1;if(this.reset(),"bool"in e&&(i=e.bool||i),"expand"in e&&(o=e.expand||o),"fields"in e)for(var r in e.fields)if(n.indexOf(r)>-1){var s=e.fields[r],u=o;void 0!=s.expand&&(u=s.expand),this.config[r]={boost:s.boost||0===s.boost?s.boost:1,bool:s.bool||i,expand:u}}else t.utils.warn("field name in user configuration not found in index instance fields");else this.addAllFields2UserConfig(i,o,n)},t.Configuration.prototype.addAllFields2UserConfig=function(e,t,n){n.forEach(function(n){this.config[n]={boost:1,bool:e,expand:t}},this)},t.Configuration.prototype.get=function(){return this.config},t.Configuration.prototype.reset=function(){this.config={}},lunr.SortedSet=function(){this.length=0,this.elements=[]},lunr.SortedSet.load=function(e){var t=new this;return t.elements=e,t.length=e.length,t},lunr.SortedSet.prototype.add=function(){var e,t;for(e=0;e<arguments.length;e++)t=arguments[e],~this.indexOf(t)||this.elements.splice(this.locationFor(t),0,t);this.length=this.elements.length},lunr.SortedSet.prototype.toArray=function(){return this.elements.slice()},lunr.SortedSet.prototype.map=function(e,t){return this.elements.map(e,t)},lunr.SortedSet.prototype.forEach=function(e,t){return this.elements.forEach(e,t)},lunr.SortedSet.prototype.indexOf=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;){if(r===e)return o;e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o]}return r===e?o:-1},lunr.SortedSet.prototype.locationFor=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;)e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o];return r>e?o:e>r?o+1:void 0},lunr.SortedSet.prototype.intersect=function(e){for(var t=new lunr.SortedSet,n=0,i=0,o=this.length,r=e.length,s=this.elements,u=e.elements;;){if(n>o-1||i>r-1)break;s[n]!==u[i]?s[n]<u[i]?n++:s[n]>u[i]&&i++:(t.add(s[n]),n++,i++)}return t},lunr.SortedSet.prototype.clone=function(){var e=new lunr.SortedSet;return e.elements=this.toArray(),e.length=e.elements.length,e},lunr.SortedSet.prototype.union=function(e){var t,n,i;this.length>=e.length?(t=this,n=e):(t=e,n=this),i=t.clone();for(var o=0,r=n.toArray();o<r.length;o++)i.add(r[o]);return i},lunr.SortedSet.prototype.toJSON=function(){return this.toArray()},function(e,t){"function"==typeof define&&define.amd?define(t):"object"==typeof exports?module.exports=t():e.elasticlunr=t()}(this,function(){return t})}();
    /** pdoc search index */const docs = [{"fullname": "animal_classification", "modulename": "animal_classification", "kind": "module", "doc": "<p>Animal Classification Project (animal_classification)</p>\n\n<p>This is the main package for the project. It contains all modules\nrequired for the Machine Learning pipeline.</p>\n\n<h3 id=\"submodules\">Submodules</h3>\n\n<ul>\n<li><strong>dataset</strong>: Functions for loading and processing the dataset.</li>\n<li><strong>download_data</strong>: Script to download the initial data.</li>\n<li><strong>delete_data</strong>: Script to clean the dataset.</li>\n<li><strong>modeling</strong>: Model definition, training, and evaluation.</li>\n<li><strong>plots</strong>: Functions for generating visualizations.</li>\n<li><strong>reduce_data</strong>: Scripts for dimensionality reduction.</li>\n<li><strong>scripts</strong>: Other helper scripts.</li>\n</ul>\n"}, {"fullname": "animal_classification.app", "modulename": "animal_classification.app", "kind": "module", "doc": "<h1 id=\"dashboard-gui-application\">Dashboard &amp; GUI Application</h1>\n\n<p>This package contains the interactive interfaces for the Animal Classification project.</p>\n\n<h2 id=\"modules\">Modules</h2>\n\n<ul>\n<li><strong>dashboard</strong>: The main Gradio-based web interface. It allows you to:\n<ul>\n<li>Train models (VGG16/VGG11) interactively.</li>\n<li>Visualize training progress (Loss/Accuracy curves).</li>\n<li>Run inference and view metrics (Confusion Matrix, ROC Curves).</li>\n</ul></li>\n</ul>\n\n<h2 id=\"how-to-run\">How to Run</h2>\n\n<p>You can launch the dashboard from the terminal using:</p>\n\n<div class=\"pdoc-code codehilite\">\n<pre><span></span><code>python<span class=\"w\"> </span>-m<span class=\"w\"> </span>animal_classification.app.dashboard\n</code></pre>\n</div>\n\n<p>Or if you installed the project:</p>\n\n<div class=\"pdoc-code codehilite\">\n<pre><span></span><code>animal-dashboard\n</code></pre>\n</div>\n"}, {"fullname": "animal_classification.app.dashboard", "modulename": "animal_classification.app.dashboard", "kind": "module", "doc": "<h1 id=\"animal-classification-dashboard\">\ud83e\udd81 Animal Classification Dashboard</h1>\n\n<p>This module launches an interactive web-based Graphical User Interface (GUI) using <strong>Gradio</strong>.</p>\n\n<p>It serves as the central control hub for the project, allowing users to perform end-to-end Machine Learning workflows without writing code.</p>\n\n<h2 id=\"features\">\ud83c\udf1f Features</h2>\n\n<ol>\n<li><strong>Interactive Training:</strong>\n<ul>\n<li>Select architectures (VGG16 vs VGG11).</li>\n<li>Configure hyperparameters (Epochs, Seed, Workers).</li>\n<li><strong>Real-time Visualization:</strong> Watch Loss and Accuracy curves update live as the model trains.</li>\n</ul></li>\n<li><strong>Model Evaluation:</strong>\n<ul>\n<li>Seamlessly pass the <em>just-trained</em> model from memory to the inference engine.</li>\n<li>Fallback to disk loading: If no model is in memory, it automatically finds the latest checkpoint in <code>models/</code>.</li>\n<li>visualizes <strong>Confusion Matrices</strong>, <strong>ROC Curves</strong>, and <strong>Calibration Plots</strong>.</li>\n</ul></li>\n</ol>\n\n<h2 id=\"how-to-run\">\ud83d\ude80 How to Run</h2>\n\n<p>Execute the following command from your project root:</p>\n\n<div class=\"pdoc-code codehilite\">\n<pre><span></span><code>python<span class=\"w\"> </span>-m<span class=\"w\"> </span>animal_classification.app.dashboard\n</code></pre>\n</div>\n\n<h2 id=\"architecture\">\ud83c\udfd7 Architecture</h2>\n\n<p>This script acts as an orchestrator. It does not contain ML logic itself but imports and executes:</p>\n\n<p>animal_classification.modeling.train.main for the training loop.</p>\n\n<p>animal_classification.modeling.inference.run_inference for evaluation.</p>\n"}, {"fullname": "animal_classification.app.dashboard.DEFAULT_DATA_DIR", "modulename": "animal_classification.app.dashboard", "qualname": "DEFAULT_DATA_DIR", "kind": "variable", "doc": "<p></p>\n", "default_value": "PosixPath(&#x27;/home/alumno/Documents/software/animal-classification/animal_classification/data/mini_animals/animals&#x27;)"}, {"fullname": "animal_classification.app.dashboard.DEFAULT_MODELS_DIR", "modulename": "animal_classification.app.dashboard", "qualname": "DEFAULT_MODELS_DIR", "kind": "variable", "doc": "<p></p>\n", "default_value": "PosixPath(&#x27;models&#x27;)"}, {"fullname": "animal_classification.app.dashboard.init_exploration", "modulename": "animal_classification.app.dashboard", "qualname": "init_exploration", "kind": "function", "doc": "<p>Initializes the data exploration tab with dataset statistics and color analysis.</p>\n\n<p>This function is triggered by the 'Load Dataset Analysis' button. It computes\nglobal dataset metrics (total classes, image counts) and generates the \nRGB profile plot using the metrics module.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>tuple</p>\n\n<pre><code>(summary_md, color_plot, dropdown_update)\n- summary_md (str): Markdown text containing class counts and image totals.\n- color_plot (PIL.Image.Image): Stacked bar chart showing average RGB profiles.\n- dropdown_update (dict): A Gradio update dictionary to populate the species selection list.\n</code></pre>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "animal_classification.app.dashboard.update_species_gallery", "modulename": "animal_classification.app.dashboard", "qualname": "update_species_gallery", "kind": "function", "doc": "<p>Retrieves and displays a gallery of image samples for the selected animal species.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>species_name : str</p>\n\n<pre><code>The folder name of the species to browse, selected from the dropdown menu.\n</code></pre>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>list</p>\n\n<pre><code>A list of PIL.Image objects representing random samples of the chosen species.\n</code></pre>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">species_name</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "animal_classification.app.dashboard.run_training", "modulename": "animal_classification.app.dashboard", "qualname": "run_training", "kind": "function", "doc": "<p>Orchestrates the training workflow triggered by the UI.</p>\n\n<p>It calls the main training script in 'demo mode' (is_demo=True), which prevents\nsaving heavy files to disk and instead returns the model object and metrics \ndirectly to memory for immediate visualization.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>model_choice : str</p>\n\n<pre><code>Dropdown selection (e.g., \"VGG16\").\n</code></pre>\n\n<p>seed : float</p>\n\n<pre><code>Random seed (cast to int internally).\n</code></pre>\n\n<p>epochs : float</p>\n\n<pre><code>Number of epochs (cast to int internally).\n</code></pre>\n\n<p>num_workers : float</p>\n\n<pre><code>Number of data loading workers.\n</code></pre>\n\n<p>progress : gradio.Progress</p>\n\n<pre><code>Automatically injected by Gradio to track the loop.\n</code></pre>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>tuple</p>\n\n<pre><code>(Trained Model Object, Metrics Markdown, Loss Figure, Accuracy Figure)\n</code></pre>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">model_choice</span>,</span><span class=\"param\">\t<span class=\"n\">seed</span>,</span><span class=\"param\">\t<span class=\"n\">epochs</span>,</span><span class=\"param\">\t<span class=\"n\">lr_choice</span>,</span><span class=\"param\">\t<span class=\"n\">num_workers</span>,</span><span class=\"param\">\t<span class=\"n\">progress</span><span class=\"o\">=&lt;</span><span class=\"n\">gradio</span><span class=\"o\">.</span><span class=\"n\">helpers</span><span class=\"o\">.</span><span class=\"n\">Progress</span> <span class=\"nb\">object</span><span class=\"o\">&gt;</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "animal_classification.app.dashboard.run_inference_gr", "modulename": "animal_classification.app.dashboard", "qualname": "run_inference_gr", "kind": "function", "doc": "<p>Orchestrates the inference/evaluation workflow.</p>\n\n<p>This function is smart about model loading:</p>\n\n<ol>\n<li><strong>Memory First:</strong> Checks if <code>trained_model</code> (passed from the Train tab via Gradio State) exists.</li>\n<li><strong>Disk Fallback:</strong> If memory is empty, searches <code>models/</code> for the most recent <code>.ckpt</code> file.</li>\n</ol>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>tuple</p>\n\n<pre><code>(Metrics Markdown, Confusion Matrix Image, ROC Curve Image, Calibration Plot Image)\n</code></pre>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">architecture</span>, </span><span class=\"param\"><span class=\"n\">trained_model</span>, </span><span class=\"param\"><span class=\"n\">batch_size</span>, </span><span class=\"param\"><span class=\"n\">num_workers</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "animal_classification.app.dashboard.create_demo", "modulename": "animal_classification.app.dashboard", "qualname": "create_demo", "kind": "function", "doc": "<p>Constructs the Gradio Blocks layout.</p>\n\n<p>Defines the Tabs, Inputs, Outputs, and event listeners (button clicks).\nIt also initializes the <code>gr.State</code> component used to share the trained model\nbetween the Training and Inference tabs.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "animal_classification.app.dashboard.main", "modulename": "animal_classification.app.dashboard", "qualname": "main", "kind": "function", "doc": "<p>Launches the Gradio web server.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "animal_classification.modeling", "modulename": "animal_classification.modeling", "kind": "module", "doc": "<p>This package contains all modules related to Machine Learning\nfor the project.</p>\n\n<p>This includes the model architecture definitions, the training \nprocess, and functions for performing inference.</p>\n\n<p>Submodules:</p>\n\n<ul>\n<li><strong>inference</strong>: Functions for loading a trained model and \nmaking predictions on new data.</li>\n<li><strong>train</strong>: Contains the pipeline and loops for training\nand evaluating the models.</li>\n</ul>\n"}, {"fullname": "animal_classification.modeling.architecture", "modulename": "animal_classification.modeling.architecture", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "animal_classification.modeling.architecture.VGGNet", "modulename": "animal_classification.modeling.architecture", "qualname": "VGGNet", "kind": "class", "doc": "<p>A VGG-based classifier implemented using PyTorch Lightning.</p>\n\n<p>This model uses a pre-trained VGG backbone (frozen features) and a custom\nclassifier head for the specific number of animal classes in the dataset.</p>\n", "bases": "lightning.pytorch.core.module.LightningModule"}, {"fullname": "animal_classification.modeling.architecture.VGGNet.__init__", "modulename": "animal_classification.modeling.architecture", "qualname": "VGGNet.__init__", "kind": "function", "doc": "<p>Args:\n    architecture (str): Backbone name ('vgg16' or 'vgg11').\n    num_classes (int): Number of output categories.\n    pretrained (bool): Whether to use ImageNet weights.\n    lr (float): Learning rate for the Adam optimizer.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">architecture</span><span class=\"o\">=</span><span class=\"s1\">&#39;vgg16&#39;</span>, </span><span class=\"param\"><span class=\"n\">num_classes</span><span class=\"o\">=</span><span class=\"mi\">90</span>, </span><span class=\"param\"><span class=\"n\">pretrained</span><span class=\"o\">=</span><span class=\"kc\">True</span>, </span><span class=\"param\"><span class=\"n\">lr</span><span class=\"o\">=</span><span class=\"mf\">0.0001</span></span>)</span>"}, {"fullname": "animal_classification.modeling.architecture.VGGNet.loss_fn", "modulename": "animal_classification.modeling.architecture", "qualname": "VGGNet.loss_fn", "kind": "variable", "doc": "<p>Standard CrossEntropyLoss for classification tasks.</p>\n"}, {"fullname": "animal_classification.modeling.architecture.VGGNet.lr", "modulename": "animal_classification.modeling.architecture", "qualname": "VGGNet.lr", "kind": "variable", "doc": "<p>Learning rate used by the optimizer.</p>\n"}, {"fullname": "animal_classification.modeling.architecture.VGGNet.forward", "modulename": "animal_classification.modeling.architecture", "qualname": "VGGNet.forward", "kind": "function", "doc": "<p>Performs the forward pass of the network.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>x : torch.Tensor\n    Input tensor containing a batch of images. \n    Shape: (batch_size, channels, height, width).</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>torch.Tensor\n    The raw output logits from the classifier head.\n    Shape: (batch_size, num_classes).</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">x</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "animal_classification.modeling.architecture.VGGNet.training_step", "modulename": "animal_classification.modeling.architecture", "qualname": "VGGNet.training_step", "kind": "function", "doc": "<p>Computes the training loss.</p>\n\n<p>Logs 'train_loss' to the progress bar and logger.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">batch</span>, </span><span class=\"param\"><span class=\"n\">batch_idx</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "animal_classification.modeling.architecture.VGGNet.validation_step", "modulename": "animal_classification.modeling.architecture", "qualname": "VGGNet.validation_step", "kind": "function", "doc": "<p>Computes validation metrics (Accuracy and Loss).</p>\n\n<p>Logs 'val_acc' and 'val_loss'.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">batch</span>, </span><span class=\"param\"><span class=\"n\">batch_idx</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "animal_classification.modeling.architecture.VGGNet.test_step", "modulename": "animal_classification.modeling.architecture", "qualname": "VGGNet.test_step", "kind": "function", "doc": "<p>Computes test accuracy on unseen data.</p>\n\n<p>Logs 'test_acc'.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">batch</span>, </span><span class=\"param\"><span class=\"n\">batch_idx</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "animal_classification.modeling.architecture.VGGNet.configure_optimizers", "modulename": "animal_classification.modeling.architecture", "qualname": "VGGNet.configure_optimizers", "kind": "function", "doc": "<p>Sets up the Adam optimizer with the specified learning rate.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "animal_classification.modeling.inference", "modulename": "animal_classification.modeling.inference", "kind": "module", "doc": "<h1 id=\"model-inference-evaluation\">\ud83d\udd0d Model Inference &amp; Evaluation</h1>\n\n<p>This module executes the inference pipeline using a trained model checkpoint.</p>\n\n<p>It handles:</p>\n\n<ol>\n<li><strong>Data Loading:</strong> Prepares the validation/test set.</li>\n<li><strong>Model Loading:</strong> Instantiates the VGG architecture and loads weights.</li>\n<li><strong>Prediction:</strong> Runs the forward pass to get probabilities.</li>\n<li><strong>Reporting:</strong> Calculates metrics (Accuracy, F1, AUC) and generates plots.</li>\n</ol>\n\n<h2 id=\"cli-usage\">\ud83d\udcbb CLI Usage</h2>\n\n<p>Run evaluation on the latest checkpoint:</p>\n\n<div class=\"pdoc-code codehilite\">\n<pre><span></span><code>python<span class=\"w\"> </span>-m<span class=\"w\"> </span>animal_classification.modeling.inference<span class=\"w\"> </span>--architecture<span class=\"w\"> </span>vgg16<span class=\"w\"> </span>--dataset-choice<span class=\"w\"> </span>mini\n</code></pre>\n</div>\n\n<p>Run on a specific model file using the full dataset:</p>\n\n<div class=\"pdoc-code codehilite\">\n<pre><span></span><code>python<span class=\"w\"> </span>-m<span class=\"w\"> </span>animal_classification.modeling.inference<span class=\"w\"> </span>--model-path<span class=\"w\"> </span>models/vgg16-best.ckpt<span class=\"w\"> </span>--dataset-choice<span class=\"w\"> </span>full\n</code></pre>\n</div>\n"}, {"fullname": "animal_classification.modeling.inference.DEFAULT_MODEL_PATTERN", "modulename": "animal_classification.modeling.inference", "qualname": "DEFAULT_MODEL_PATTERN", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;models/*.ckpt&#x27;"}, {"fullname": "animal_classification.modeling.inference.DEFAULT_OUTPUT_PATH", "modulename": "animal_classification.modeling.inference", "qualname": "DEFAULT_OUTPUT_PATH", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;reports/inference&#x27;"}, {"fullname": "animal_classification.modeling.inference.run_inference", "modulename": "animal_classification.modeling.inference", "qualname": "run_inference", "kind": "function", "doc": "<p>Executes the full inference pipeline on the validation dataset.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>model_path : Path, optional</p>\n\n<pre><code>Path to the `.ckpt` checkpoint file. Required if `trained_model` is None.\n</code></pre>\n\n<p>data_dir : Path, optional.</p>\n\n<pre><code>Path to the dataset directory\n</code></pre>\n\n<p>architecture : str.</p>\n\n<pre><code>Model architecture name ('vgg16' or 'vgg11')\n</code></pre>\n\n<p>trained_model : pl.LightningModule, optional</p>\n\n<pre><code>An in-memory model object (used by the Dashboard). If provided, `model_path` is ignored.\n</code></pre>\n\n<p>output_path : Path, optional</p>\n\n<pre><code>Directory to save results (arrays and plots). Ignored in demo mode.\n</code></pre>\n\n<p>batch_size : int</p>\n\n<pre><code>Batch size for inference.\n</code></pre>\n\n<p>num_workers : int</p>\n\n<pre><code>Number of data loading workers.\n</code></pre>\n\n<p>is_demo : bool</p>\n\n<pre><code>If `True`, returns raw objects for the UI instead of saving to disk.\n</code></pre>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>tuple (if is_demo=True)</p>\n\n<pre><code>(probs, labels, accuracy, f1_macro, confusion_matrix_img, roc_img, calibration_img)\n</code></pre>\n\n<p>dict (if is_demo=False).</p>\n\n<pre><code>Dictionary containing metrics and the output path.\n</code></pre>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">model_path</span><span class=\"p\">:</span> <span class=\"n\">pathlib</span><span class=\"o\">.</span><span class=\"n\">Path</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">data_dir</span><span class=\"p\">:</span> <span class=\"n\">pathlib</span><span class=\"o\">.</span><span class=\"n\">Path</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">architecture</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;vgg16&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">trained_model</span><span class=\"p\">:</span> <span class=\"n\">lightning</span><span class=\"o\">.</span><span class=\"n\">pytorch</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">LightningModule</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">output_path</span><span class=\"p\">:</span> <span class=\"n\">pathlib</span><span class=\"o\">.</span><span class=\"n\">Path</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">batch_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">16</span>,</span><span class=\"param\">\t<span class=\"n\">num_workers</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">2</span>,</span><span class=\"param\">\t<span class=\"n\">is_demo</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "animal_classification.modeling.inference.extract_version", "modulename": "animal_classification.modeling.inference", "qualname": "extract_version", "kind": "function", "doc": "<p>Extracts the version number from a PyTorch Lightning checkpoint filename.</p>\n\n<p>PyTorch Lightning often appends '-v1', '-v2', etc., to checkpoints if \nmultiple versions exist. This function parses that integer to help \nidentify the most recent or 'highest' versioned file.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>filepath : str</p>\n\n<pre><code>The full path or filename of the checkpoint.\n</code></pre>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>int</p>\n\n<pre><code>The version number extracted (e.g., 2 from 'vgg16-v2.ckpt'). \nReturns 0 if no version pattern is found.\n</code></pre>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">filepath</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "animal_classification.modeling.inference.main", "modulename": "animal_classification.modeling.inference", "qualname": "main", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "animal_classification.modeling.metrics", "modulename": "animal_classification.modeling.metrics", "kind": "module", "doc": "<h1 id=\"model-visualization-metrics\">\ud83d\udcca Model Visualization &amp; Metrics</h1>\n\n<p>This module contains helper functions to generate diagnostic plots for model evaluation.\nIt supports generating:</p>\n\n<ul>\n<li><strong>Confusion Matrices</strong>: To see where the model is confusing classes.</li>\n<li><strong>ROC Curves</strong>: To evaluate the trade-off between sensitivity and specificity.</li>\n<li><strong>Calibration Curves</strong>: To check if the model's confidence scores are reliable.</li>\n</ul>\n\n<p>These functions handle the logic of switching between saving to disk (CLI mode) \nand returning PIL images (Dashboard mode).</p>\n"}, {"fullname": "animal_classification.modeling.metrics.get_dataset_stats", "modulename": "animal_classification.modeling.metrics", "qualname": "get_dataset_stats", "kind": "function", "doc": "<p>Calculates basic statistics for the dataset exploration tab.</p>\n\n<p>Inspects the provided directory to count classes and filter valid image files\nto provide a summary of the dataset's composition.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>data_dir : Path</p>\n\n<pre><code>The root directory containing animal class subfolders.\n</code></pre>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>tuple\n    A tuple containing (pd.DataFrame of counts per species, \n    int total_number_of_classes, int total_image_count, \n    list_of_species_names).</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">data_dir</span><span class=\"p\">:</span> <span class=\"n\">pathlib</span><span class=\"o\">.</span><span class=\"n\">Path</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "animal_classification.modeling.metrics.get_species_samples", "modulename": "animal_classification.modeling.metrics", "qualname": "get_species_samples", "kind": "function", "doc": "<p>Returns a list of random PIL images for a specific animal species. </p>\n\n<p>This function filters for common image extensions to prevent loading \nmetadata or hidden system files and provides samples for UI visualization.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>data_dir : Path</p>\n\n<pre><code>The root directory of the dataset.\n</code></pre>\n\n<p>species_name : str</p>\n\n<pre><code>The folder name of the target species.\n</code></pre>\n\n<p>num_samples : int, optional</p>\n\n<pre><code>Maximum number of samples to retrieve (default: 8).\n</code></pre>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>list\n    A list of PIL.Image objects corresponding to the sampled images.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">data_dir</span><span class=\"p\">:</span> <span class=\"n\">pathlib</span><span class=\"o\">.</span><span class=\"n\">Path</span>, </span><span class=\"param\"><span class=\"n\">species_name</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">num_samples</span><span class=\"o\">=</span><span class=\"mi\">8</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "animal_classification.modeling.metrics.plot_color_analysis", "modulename": "animal_classification.modeling.metrics", "qualname": "plot_color_analysis", "kind": "function", "doc": "<p>Performs RGB profile analysis on a subset of classes for visualization.</p>\n\n<p>Computes the average R, G, and B channel intensities across a sample of \nspecies to visualize color dominance in different animal groups. \nLimited to 25 species for plot readability.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>data_dir : Path</p>\n\n<pre><code>The directory containing the class folders.\n</code></pre>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>PIL.Image.Image</p>\n\n<pre><code>The generated stacked bar plot as a PIL image object.\n</code></pre>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">data_dir</span><span class=\"p\">:</span> <span class=\"n\">pathlib</span><span class=\"o\">.</span><span class=\"n\">Path</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "animal_classification.modeling.metrics.fig_to_image", "modulename": "animal_classification.modeling.metrics", "qualname": "fig_to_image", "kind": "function", "doc": "<p>Converts a Matplotlib figure into a PIL Image.</p>\n\n<p>This is used primarily by the Gradio dashboard to display plots \nin memory without saving them to disk.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>fig : matplotlib.figure.Figure, optional</p>\n\n<pre><code>The figure to convert. If None, uses the current active figure.\n</code></pre>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>PIL.Image.Image</p>\n\n<pre><code>The plot rendered as an image object.\n</code></pre>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">fig</span><span class=\"o\">=</span><span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "animal_classification.modeling.metrics.plot_training_curves", "modulename": "animal_classification.modeling.metrics", "qualname": "plot_training_curves", "kind": "function", "doc": "<p>Generates dual-axis convergence plots for training/validation performance.</p>\n\n<p>Visualizes how loss decreases and accuracy increases over training epochs,\nproviding immediate feedback on model learning and potential overfitting.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>train_loss : list\n    Historical values of training loss per epoch.</p>\n\n<p>val_loss : list</p>\n\n<pre><code>Historical values of validation loss per epoch.\n</code></pre>\n\n<p>val_acc : list</p>\n\n<pre><code>Historical values of validation accuracy per epoch.\n</code></pre>\n\n<p>architecture_name : str, optional</p>\n\n<pre><code>Name of the model backbone used (default: \"Model\").\n</code></pre>\n\n<p>output_path : Path, optional</p>\n\n<pre><code>Filesystem path to save the generated image (ignored if is_demo is True).\n</code></pre>\n\n<p>is_demo : bool, optional</p>\n\n<pre><code>If True, returns the plot as a PIL Image object (default: False).\n</code></pre>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>PIL.Image.Image or None\n    Returns the image object if in demo mode, otherwise None.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">train_loss</span>,</span><span class=\"param\">\t<span class=\"n\">val_loss</span>,</span><span class=\"param\">\t<span class=\"n\">val_acc</span>,</span><span class=\"param\">\t<span class=\"n\">architecture_name</span><span class=\"o\">=</span><span class=\"s1\">&#39;Model&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">output_path</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">is_demo</span><span class=\"o\">=</span><span class=\"kc\">False</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "animal_classification.modeling.metrics.plot_confusion_matrix", "modulename": "animal_classification.modeling.metrics", "qualname": "plot_confusion_matrix", "kind": "function", "doc": "<p>Generates a Confusion Matrix to visualize misclassifications.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>y_true : array-like</p>\n\n<pre><code>Ground truth (correct) target values.\n</code></pre>\n\n<p>y_pred : array-like</p>\n\n<pre><code>Estimated targets as returned by a classifier.\n</code></pre>\n\n<p>architecture_name : str</p>\n\n<pre><code>Name of the model (for the plot title).\n</code></pre>\n\n<p>output_path : Path, optional</p>\n\n<pre><code>Directory to save the `.png` file if `is_demo=False`.\n</code></pre>\n\n<p>is_demo : bool</p>\n\n<pre><code>If True, returns a PIL Image instead of saving to disk.\n</code></pre>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>PIL.Image.Image or numpy.ndarray</p>\n\n<pre><code>Returns the PIL Image if `is_demo=True`.\nReturns the raw confusion matrix array if `is_demo=False`.\n</code></pre>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">y_true</span>,</span><span class=\"param\">\t<span class=\"n\">y_pred</span>,</span><span class=\"param\">\t<span class=\"n\">architecture_name</span><span class=\"o\">=</span><span class=\"s1\">&#39;Model&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">output_path</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">is_demo</span><span class=\"o\">=</span><span class=\"kc\">False</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "animal_classification.modeling.metrics.plot_roc_curves", "modulename": "animal_classification.modeling.metrics", "qualname": "plot_roc_curves", "kind": "function", "doc": "<p>Generates Macro-Average ROC Curves.</p>\n\n<p>Calculates the Receiver Operating Characteristic (ROC) curve for each class \nand computes the macro-average AUC score.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>y_true : array-like</p>\n\n<pre><code>Ground truth labels.\n</code></pre>\n\n<p>y_probs : array-like</p>\n\n<pre><code>Probability estimates of the positive class.\n</code></pre>\n\n<p>num_classes : int</p>\n\n<pre><code>Total number of classes.\n</code></pre>\n\n<p>architecture_name : str</p>\n\n<pre><code>Name of the model.\n</code></pre>\n\n<p>output_path : Path, optional</p>\n\n<pre><code>Path to save the plot.\n</code></pre>\n\n<p>is_demo : bool</p>\n\n<pre><code>If True, returns the plot as an image and the AUC score.\n</code></pre>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>tuple</p>\n\n<pre><code>A tuple containing (PIL.Image.Image, float_auc_score) if `is_demo=True`.\nA tuple containing (None, float_auc_score) if `is_demo=False`.\n</code></pre>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">y_true</span>,</span><span class=\"param\">\t<span class=\"n\">y_probs</span>,</span><span class=\"param\">\t<span class=\"n\">num_classes</span>,</span><span class=\"param\">\t<span class=\"n\">architecture_name</span><span class=\"o\">=</span><span class=\"s1\">&#39;Model&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">output_path</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">is_demo</span><span class=\"o\">=</span><span class=\"kc\">False</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "animal_classification.modeling.metrics.plot_calibration_curve", "modulename": "animal_classification.modeling.metrics", "qualname": "plot_calibration_curve", "kind": "function", "doc": "<p>Generates a Reliability Diagram (Calibration Curve).</p>\n\n<p>Compares the model's predicted probability against the actual frequency of the class.\nA perfectly calibrated model will follow the diagonal line.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>y_true : array-like</p>\n\n<pre><code>True labels.\n</code></pre>\n\n<p>y_probs : array-like</p>\n\n<pre><code>Predicted probabilities.\n</code></pre>\n\n<p>num_classes : int</p>\n\n<pre><code>Number of classes.\n</code></pre>\n\n<p>architecture_name : str</p>\n\n<pre><code>Name of the model.\n</code></pre>\n\n<p>output_path : Path, optional</p>\n\n<pre><code>Save location on the filesystem.\n</code></pre>\n\n<p>is_demo : bool</p>\n\n<pre><code>If True, returns the generated plot as a PIL image object.\n</code></pre>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>PIL.Image.Image or None</p>\n\n<pre><code>The reliability diagram image object if is_demo is True, otherwise None.\n</code></pre>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">y_true</span>,</span><span class=\"param\">\t<span class=\"n\">y_probs</span>,</span><span class=\"param\">\t<span class=\"n\">num_classes</span>,</span><span class=\"param\">\t<span class=\"n\">architecture_name</span><span class=\"o\">=</span><span class=\"s1\">&#39;Model&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">output_path</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">is_demo</span><span class=\"o\">=</span><span class=\"kc\">False</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "animal_classification.modeling.train", "modulename": "animal_classification.modeling.train", "kind": "module", "doc": "<h1 id=\"model-training-orchestrator\">\ud83d\ude82 Model Training Orchestrator</h1>\n\n<p>This module handles the end-to-end training pipeline using <strong>PyTorch Lightning</strong>.</p>\n\n<p>It is designed to be run in two modes:</p>\n\n<ol>\n<li><strong>CLI Mode:</strong> From the terminal, saving results to <code>models/</code> and <code>logs/</code>.</li>\n<li><strong>Demo Mode:</strong> From the Dashboard, keeping results in memory.</li>\n</ol>\n\n<h2 id=\"cli-usage\">\ud83d\udcbb CLI Usage</h2>\n\n<p>You can train a model directly from your terminal:</p>\n\n<div class=\"pdoc-code codehilite\">\n<pre><span></span><code><span class=\"c1\"># Train VGG16 for 10 epochs on the mini dataset</span>\npython<span class=\"w\"> </span>-m<span class=\"w\"> </span>animal_classification.modeling.train<span class=\"w\"> </span>--architecture<span class=\"w\"> </span>vgg16<span class=\"w\"> </span>--max-epochs<span class=\"w\"> </span><span class=\"m\">10</span><span class=\"w\"> </span>--lr<span class=\"w\"> </span>1e-4\n</code></pre>\n</div>\n"}, {"fullname": "animal_classification.modeling.train.GradioProgressCallback", "modulename": "animal_classification.modeling.train", "qualname": "GradioProgressCallback", "kind": "class", "doc": "<p>Lightning callback to synchronize training progress with the Gradio UI.</p>\n\n<p>This class hooks into the training loop's batch-end events to calculate \nthe overall completion percentage and update the progress bar provided \nby the Gradio web interface.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>progress_fn : gradio.Progress</p>\n\n<pre><code>The progress tracker instance injected by the Gradio interface.\n</code></pre>\n\n<p>max_epochs : int</p>\n\n<pre><code>The total number of epochs configured for the training run.\n</code></pre>\n\n<p>total_batches : int</p>\n\n<pre><code>Cached count of training batches per epoch.\n</code></pre>\n", "bases": "lightning.pytorch.callbacks.callback.Callback"}, {"fullname": "animal_classification.modeling.train.GradioProgressCallback.__init__", "modulename": "animal_classification.modeling.train", "qualname": "GradioProgressCallback.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">progress_fn</span>, </span><span class=\"param\"><span class=\"n\">max_epochs</span></span>)</span>"}, {"fullname": "animal_classification.modeling.train.GradioProgressCallback.progress_fn", "modulename": "animal_classification.modeling.train", "qualname": "GradioProgressCallback.progress_fn", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "animal_classification.modeling.train.GradioProgressCallback.max_epochs", "modulename": "animal_classification.modeling.train", "qualname": "GradioProgressCallback.max_epochs", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "animal_classification.modeling.train.GradioProgressCallback.total_batches", "modulename": "animal_classification.modeling.train", "qualname": "GradioProgressCallback.total_batches", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "animal_classification.modeling.train.GradioProgressCallback.on_train_batch_end", "modulename": "animal_classification.modeling.train", "qualname": "GradioProgressCallback.on_train_batch_end", "kind": "function", "doc": "<p>Called when the train batch ends.</p>\n\n<p>Note:\n    The value <code>outputs[\"loss\"]</code> here will be the normalized value w.r.t <code>accumulate_grad_batches</code> of the\n    loss returned from <code>training_step</code>.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">trainer</span>, </span><span class=\"param\"><span class=\"n\">pl_module</span>, </span><span class=\"param\"><span class=\"n\">outputs</span>, </span><span class=\"param\"><span class=\"n\">batch</span>, </span><span class=\"param\"><span class=\"n\">batch_idx</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "animal_classification.modeling.train.train_model", "modulename": "animal_classification.modeling.train", "qualname": "train_model", "kind": "function", "doc": "<p>Executes the training pipeline.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>architecture : str.</p>\n\n<pre><code>The model backbone to use. Options: `'vgg16'`, `'vgg11'`.\n</code></pre>\n\n<p>dataset_choice : str.</p>\n\n<pre><code>Which dataset folder to use. Options: `'mini'` (default), `'full'`.\n</code></pre>\n\n<p>seed : int.</p>\n\n<pre><code>Random seed for reproducibility.\n</code></pre>\n\n<p>test_frac : float.</p>\n\n<pre><code>Fraction of data to hold out for testing.\n</code></pre>\n\n<p>max_epochs : int.</p>\n\n<pre><code>Total number of training epochs.\n</code></pre>\n\n<p>batch_size : int.</p>\n\n<pre><code>Number of images per training batch.\n</code></pre>\n\n<p>num_workers : int.</p>\n\n<pre><code>Number of CPU subprocesses for data loading.\n</code></pre>\n\n<p>is_demo : bool.</p>\n\n<pre><code>If `True`, runs in Dashboard mode (in-memory).\n</code></pre>\n\n<p>progress : gradio.Progress, optional</p>\n\n<pre><code>Gradio progress tracker.\n</code></pre>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>dict</p>\n\n<pre><code>A dictionary containing training metrics and the model object.\n</code></pre>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">architecture</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;vgg16&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">dataset_choice</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;mini&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">seed</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">42</span>,</span><span class=\"param\">\t<span class=\"n\">test_frac</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.2</span>,</span><span class=\"param\">\t<span class=\"n\">max_epochs</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">5</span>,</span><span class=\"param\">\t<span class=\"n\">batch_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">16</span>,</span><span class=\"param\">\t<span class=\"n\">lr</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.001</span>,</span><span class=\"param\">\t<span class=\"n\">num_workers</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">2</span>,</span><span class=\"param\">\t<span class=\"n\">is_demo</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">progress</span><span class=\"p\">:</span> <span class=\"n\">gradio</span><span class=\"o\">.</span><span class=\"n\">helpers</span><span class=\"o\">.</span><span class=\"n\">Progress</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "animal_classification.modeling.train.main", "modulename": "animal_classification.modeling.train", "qualname": "main", "kind": "function", "doc": "<p>Command-line interface entry point. \nThis parses arguments and then calls the logic in train_model().</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "animal_classification.preprocessing", "modulename": "animal_classification.preprocessing", "kind": "module", "doc": "<h1 id=\"preprocessing-data-management\">Preprocessing &amp; Data Management</h1>\n\n<p>This module handles the preparation of data before it enters the model. \nIt includes the PyTorch Lightning DataModule for training and scripts for \nmanaging the raw dataset.</p>\n\n<h2 id=\"components\">Components</h2>\n\n<ul>\n<li><strong>AnimalsDataModule</strong>: The main class that handles loading, splitting, and transforming images.</li>\n</ul>\n\n<h2 id=\"scripts\">Scripts</h2>\n\n<p>This folder also contains standalone scripts for data management:</p>\n\n<ul>\n<li><code>download_data.py</code>: Downloads the raw images.</li>\n<li><code>reduce_data.py</code>: Resizes huge images to save space.</li>\n<li><code>delete_data.py</code>: Cleans up the dataset.</li>\n</ul>\n"}, {"fullname": "animal_classification.preprocessing.dataset", "modulename": "animal_classification.preprocessing.dataset", "kind": "module", "doc": "<h1 id=\"animals-data-module\">\ud83d\uddbc\ufe0f Animals Data Module</h1>\n\n<p>This module handles the loading and preprocessing of the animal images.\nIt uses PyTorch Lightning's <code>DataModule</code> to organize:</p>\n\n<ol>\n<li><strong>Transformations:</strong> Mandatory normalization and Data Augmentation for training.</li>\n<li><strong>Splitting:</strong> Dividing the dataset into training and validation sets.</li>\n<li><strong>Dataloaders:</strong> Batching and shuffling for CPU/GPU processing.</li>\n</ol>\n"}, {"fullname": "animal_classification.preprocessing.dataset.AnimalsDataModule", "modulename": "animal_classification.preprocessing.dataset", "qualname": "AnimalsDataModule", "kind": "class", "doc": "<p>LightningDataModule for the Animal Image Dataset.</p>\n\n<p>Ensures that images are augmented during training and normalized \ncorrectly for pre-trained VGG architectures. It manages the full\nlifecycle of data loading, from raw images on disk to batched tensors.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>train_ds : Subset</p>\n\n<pre><code>The training subset with data augmentation applied.\n</code></pre>\n\n<p>val_ds : Subset</p>\n\n<pre><code>The validation subset with deterministic transformations.\n</code></pre>\n\n<p>class_names : list</p>\n\n<pre><code>List of strings containing the animal species names.\n</code></pre>\n", "bases": "lightning.pytorch.core.datamodule.LightningDataModule"}, {"fullname": "animal_classification.preprocessing.dataset.AnimalsDataModule.__init__", "modulename": "animal_classification.preprocessing.dataset", "qualname": "AnimalsDataModule.__init__", "kind": "function", "doc": "<p>Initialize the DataModule with directory paths and hyper-parameters.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>data_dir : str</p>\n\n<pre><code>Path to the root directory containing species subfolders.\n</code></pre>\n\n<p>batch_size : int, optional</p>\n\n<pre><code>Number of images per training/validation batch (default: 16).\n</code></pre>\n\n<p>seed : int, optional</p>\n\n<pre><code>Random seed for reproducible data splitting (default: 42).\n</code></pre>\n\n<p>test_frac : float, optional</p>\n\n<pre><code>The proportion of the dataset to include in the validation split (default: 0.2).\n</code></pre>\n\n<p>num_workers : int, optional</p>\n\n<pre><code>Number of subprocesses to use for data loading (default: 2).\n</code></pre>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">data_dir</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">batch_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">16</span>,</span><span class=\"param\">\t<span class=\"n\">seed</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">42</span>,</span><span class=\"param\">\t<span class=\"n\">test_frac</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.2</span>,</span><span class=\"param\">\t<span class=\"n\">num_workers</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">2</span></span>)</span>"}, {"fullname": "animal_classification.preprocessing.dataset.AnimalsDataModule.data_dir", "modulename": "animal_classification.preprocessing.dataset", "qualname": "AnimalsDataModule.data_dir", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "animal_classification.preprocessing.dataset.AnimalsDataModule.batch_size", "modulename": "animal_classification.preprocessing.dataset", "qualname": "AnimalsDataModule.batch_size", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "animal_classification.preprocessing.dataset.AnimalsDataModule.seed", "modulename": "animal_classification.preprocessing.dataset", "qualname": "AnimalsDataModule.seed", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "animal_classification.preprocessing.dataset.AnimalsDataModule.test_frac", "modulename": "animal_classification.preprocessing.dataset", "qualname": "AnimalsDataModule.test_frac", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "animal_classification.preprocessing.dataset.AnimalsDataModule.num_workers", "modulename": "animal_classification.preprocessing.dataset", "qualname": "AnimalsDataModule.num_workers", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "animal_classification.preprocessing.dataset.AnimalsDataModule.train_transform", "modulename": "animal_classification.preprocessing.dataset", "qualname": "AnimalsDataModule.train_transform", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "animal_classification.preprocessing.dataset.AnimalsDataModule.val_transform", "modulename": "animal_classification.preprocessing.dataset", "qualname": "AnimalsDataModule.val_transform", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "animal_classification.preprocessing.dataset.AnimalsDataModule.setup", "modulename": "animal_classification.preprocessing.dataset", "qualname": "AnimalsDataModule.setup", "kind": "function", "doc": "<p>Loads the dataset and performs the train/validation split.</p>\n\n<p>Creates two distinct transformation pipelines for each subset while ensuring\nthat the same random indices are used to avoid data leakage.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>stage : str, optional</p>\n\n<pre><code>The stage for which the setup is called ('fit' or 'test'). \nDefaults to None.\n</code></pre>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">stage</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "animal_classification.preprocessing.dataset.AnimalsDataModule.train_dataloader", "modulename": "animal_classification.preprocessing.dataset", "qualname": "AnimalsDataModule.train_dataloader", "kind": "function", "doc": "<p>Constructs the training data loader.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>DataLoader</p>\n\n<pre><code>The batched and shuffled training data loader.\n</code></pre>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "animal_classification.preprocessing.dataset.AnimalsDataModule.val_dataloader", "modulename": "animal_classification.preprocessing.dataset", "qualname": "AnimalsDataModule.val_dataloader", "kind": "function", "doc": "<p>Constructs the validation data loader.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>DataLoader</p>\n\n<pre><code>The batched validation data loader (not shuffled).\n</code></pre>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "animal_classification.preprocessing.dataset.AnimalsDataModule.test_dataloader", "modulename": "animal_classification.preprocessing.dataset", "qualname": "AnimalsDataModule.test_dataloader", "kind": "function", "doc": "<p>Constructs the test data loader. \nNote: Currently uses the validation split for consistency during internal evaluation.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>DataLoader</p>\n\n<pre><code>The batched test data loader.\n</code></pre>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "animal_classification.preprocessing.delete_data", "modulename": "animal_classification.preprocessing.delete_data", "kind": "module", "doc": "<p>Script to completely remove dataset folders.</p>\n\n<p>This script iterates through the root data folder and deletes\nall subdirectories (e.g., 'cat', 'dog') entirely.</p>\n"}, {"fullname": "animal_classification.preprocessing.delete_data.main", "modulename": "animal_classification.preprocessing.delete_data", "qualname": "main", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "animal_classification.preprocessing.download_data", "modulename": "animal_classification.preprocessing.download_data", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "animal_classification.preprocessing.download_data.flatten_folder", "modulename": "animal_classification.preprocessing.download_data", "qualname": "flatten_folder", "kind": "function", "doc": "<p>Recursively flattens a directory structure.</p>\n\n<p>If a folder contains exactly one subfolder and no files,\nthis function descends into that subfolder repeatedly until it finds\na directory with actual content (files or multiple folders).</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>path : Path</p>\n\n<pre><code>The initial directory path to inspect.\n</code></pre>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>Path</p>\n\n<pre><code>The path to the deepest single-child subdirectory found,\nor the original path if no flattening was needed.\n</code></pre>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">path</span><span class=\"p\">:</span> <span class=\"n\">pathlib</span><span class=\"o\">.</span><span class=\"n\">Path</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pathlib</span><span class=\"o\">.</span><span class=\"n\">Path</span>:</span></span>", "funcdef": "def"}, {"fullname": "animal_classification.preprocessing.download_data.main", "modulename": "animal_classification.preprocessing.download_data", "qualname": "main", "kind": "function", "doc": "<p>Download, flatten, and copy dataset to 'data/animals'.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "animal_classification.preprocessing.reduce_data", "modulename": "animal_classification.preprocessing.reduce_data", "kind": "module", "doc": "<p>Dataset Reduction Utility.</p>\n\n<p>Reduces an image dataset by sampling a fixed number of images per class\nand resizing them to a uniform size. Saves reduced dataset to ../data/mini_animals/animals</p>\n"}, {"fullname": "animal_classification.preprocessing.reduce_data.reduce_dataset", "modulename": "animal_classification.preprocessing.reduce_data", "qualname": "reduce_dataset", "kind": "function", "doc": "<p>Reduces the animal dataset by sampling and resizing images.</p>\n\n<p>It clears the output directory if it exists and repopulates it with\nthe sampled images.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>images_per_class : int.</p>\n\n<pre><code>Number of images to randomly select and save for each class.\n</code></pre>\n\n<p>image_size : int.</p>\n\n<pre><code>The target width and height (in pixels) to resize images to.\n</code></pre>\n\n<p>progress : callable, optional.</p>\n\n<pre><code>A callback function to update progress bars (e.g., for Gradio).\nShould accept a float (0.0 to 1.0) and a description string.\n</code></pre>\n\n<p>seed : int, optional.</p>\n\n<pre><code>Random seed for reproducibility (default is 123).\n</code></pre>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">images_per_class</span>, </span><span class=\"param\"><span class=\"n\">image_size</span>, </span><span class=\"param\"><span class=\"n\">progress</span><span class=\"o\">=</span><span class=\"kc\">None</span>, </span><span class=\"param\"><span class=\"n\">seed</span><span class=\"o\">=</span><span class=\"mi\">123</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "animal_classification.preprocessing.reduce_data.main", "modulename": "animal_classification.preprocessing.reduce_data", "qualname": "main", "kind": "function", "doc": "<p>CLI entry point.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "animal_classification.utils", "modulename": "animal_classification.utils", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "animal_classification.utils.get_accelerator", "modulename": "animal_classification.utils", "qualname": "get_accelerator", "kind": "function", "doc": "<p>Determines the hardware accelerator to use (GPU or CPU).</p>\n\n<p>This function checks if CUDA is available and performs a sanity check\nby attempting to access device properties. If CUDA is reported as\navailable but fails the check (e.g., due to driver issues), it gracefully\nfalls back to CPU and prints a warning.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>str\n    Returns \"gpu\" if a CUDA device is available and functioning,\n    otherwise returns \"cpu\".</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "animal_classification.utils.get_packaged_mini_data_path", "modulename": "animal_classification.utils", "qualname": "get_packaged_mini_data_path", "kind": "function", "doc": "<p>Locates the 'mini_animals' dataset directory.</p>\n\n<p>This function attempts to find the dataset inside the installed package\n(site-packages) using <code>importlib.resources</code>. If the package is not\ninstalled (e.g., during local development), it falls back to the\nrelative local path.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>pathlib.Path</p>\n\n<pre><code>The path object pointing to the 'mini_animals/animals' directory.\n</code></pre>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}];

    // mirrored in build-search-index.js (part 1)
    // Also split on html tags. this is a cheap heuristic, but good enough.
    elasticlunr.tokenizer.setSeperator(/[\s\-.;&_'"=,()]+|<[^>]*>/);

    let searchIndex;
    if (docs._isPrebuiltIndex) {
        console.info("using precompiled search index");
        searchIndex = elasticlunr.Index.load(docs);
    } else {
        console.time("building search index");
        // mirrored in build-search-index.js (part 2)
        searchIndex = elasticlunr(function () {
            this.pipeline.remove(elasticlunr.stemmer);
            this.pipeline.remove(elasticlunr.stopWordFilter);
            this.addField("qualname");
            this.addField("fullname");
            this.addField("annotation");
            this.addField("default_value");
            this.addField("signature");
            this.addField("bases");
            this.addField("doc");
            this.setRef("fullname");
        });
        for (let doc of docs) {
            searchIndex.addDoc(doc);
        }
        console.timeEnd("building search index");
    }

    return (term) => searchIndex.search(term, {
        fields: {
            qualname: {boost: 4},
            fullname: {boost: 2},
            annotation: {boost: 2},
            default_value: {boost: 2},
            signature: {boost: 2},
            bases: {boost: 2},
            doc: {boost: 1},
        },
        expand: true
    });
})();